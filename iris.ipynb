{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFX version: 1.3.3\n",
      "TensorFlow version: 2.6.2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tfx import v1 as tfx\n",
    "\n",
    "from tfx.orchestration.experimental.interactive.interactive_context import InteractiveContext\n",
    "\n",
    "%load_ext tfx.orchestration.experimental.interactive.notebook_extensions.skip\n",
    "\n",
    "print('TFX version: {}'.format(tfx.__version__))\n",
    "print('TensorFlow version: {}'.format(tf.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from absl import logging\n",
    "\n",
    "PIPELINE_NAME = \"iris\"\n",
    "PIPELINE_ROOT = os.path.join('pipelines', PIPELINE_NAME)\n",
    "METADATA_PATH = os.path.join('metadata', PIPELINE_NAME, 'metadata.db')\n",
    "SERVING_MODEL_DIR = os.path.join('serving_model', PIPELINE_NAME)\n",
    "\n",
    "DATA_ROOT = os.path.join(\"data\")\n",
    "\n",
    "logging.set_verbosity(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import urllib.request\n",
    "\n",
    "_data_url = 'https://forge.scilab.org/index.php/p/rdataset/source/file/master/csv/datasets/iris.csv'\n",
    "_download_filepath = os.path.join(DATA_ROOT, \"iris.csv\")\n",
    "_data_filepath = os.path.join(DATA_ROOT, \"data.csv\")\n",
    "\n",
    "urllib.request.urlretrieve(_data_url, _download_filepath)\n",
    "\n",
    "with open(_download_filepath, 'r') as infile, open(_data_filepath, 'w') as outfile:\n",
    "    r = csv.reader(infile)\n",
    "    w = csv.writer(outfile)\n",
    "\n",
    "    next(r, None)\n",
    "    w.writerow([\"id\", \"Sepal.Length\", \"Sepal.Width\", \"Petal.Length\", \"Petal.Width\", \"Species\"])\n",
    "\n",
    "    for row in r:\n",
    "        w.writerow(row)\n",
    "\n",
    "os.remove(_download_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id,Sepal.Length,Sepal.Width,Petal.Length,Petal.Width,Species\r",
      "\r\n",
      "1,5.1,3.5,1.4,0.2,setosa\r",
      "\r\n",
      "2,4.9,3,1.4,0.2,setosa\r",
      "\r\n",
      "3,4.7,3.2,1.3,0.2,setosa\r",
      "\r\n",
      "4,4.6,3.1,1.5,0.2,setosa\r",
      "\r\n",
      "5,5,3.6,1.4,0.2,setosa\r",
      "\r\n",
      "6,5.4,3.9,1.7,0.4,setosa\r",
      "\r\n",
      "7,4.6,3.4,1.4,0.3,setosa\r",
      "\r\n",
      "8,5,3.4,1.5,0.2,setosa\r",
      "\r\n",
      "9,4.4,2.9,1.4,0.2,setosa\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!head {_data_filepath}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create TFX pipeline and run it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "_module_file = 'iris_utils.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow_model_analysis as tfma\n",
    "\n",
    "def _create_pipeline(pipeline_name: str, pipeline_root: str, data_root: str,\n",
    "                     module_file: str, serving_model_dir: str,\n",
    "                     metadata_path: str) -> tfx.dsl.Pipeline:\n",
    "    \"\"\"Implements the penguin pipeline with TFX.\"\"\"\n",
    "    # Brings data into the pipeline or otherwise joins/converts training data.\n",
    "    example_gen = tfx.components.CsvExampleGen(input_base=data_root)\n",
    "\n",
    "    # Computes statistics over data for visualization and example validation.\n",
    "    statistics_gen = tfx.components.StatisticsGen(\n",
    "        examples=example_gen.outputs['examples'])\n",
    "\n",
    "    # Generate a schema based on your data statistics.\n",
    "    # A schema defines the expected bounds, types, and properties of the features in your dataset.\n",
    "    schema_gen = tfx.components.SchemaGen(\n",
    "        statistics=statistics_gen.outputs['statistics'], infer_feature_shape=True)\n",
    "\n",
    "    # Performs anomaly detection based on statistics and data schema.\n",
    "    example_validator = tfx.components.ExampleValidator(\n",
    "        statistics=statistics_gen.outputs['statistics'],\n",
    "        schema=schema_gen.outputs['schema'])\n",
    "\n",
    "    # Transforms input data using preprocessing_fn in the 'module_file'.\n",
    "    transform = tfx.components.Transform(\n",
    "        examples=example_gen.outputs['examples'],\n",
    "        schema=schema_gen.outputs['schema'],\n",
    "        materialize=False,\n",
    "        module_file=module_file)\n",
    "\n",
    "    # Uses user-provided Python function that trains a model.\n",
    "    trainer = tfx.components.Trainer(\n",
    "        module_file=module_file,\n",
    "        examples=example_gen.outputs['examples'],\n",
    "        schema=schema_gen.outputs['schema'],\n",
    "        transform_graph=transform.outputs['transform_graph'],\n",
    "        train_args=tfx.proto.TrainArgs(num_steps=2000),\n",
    "        eval_args=tfx.proto.EvalArgs(num_steps=5))\n",
    "\n",
    "    # Pushes the model to a filesystem destination.\n",
    "    pusher = tfx.components.Pusher(\n",
    "        model=trainer.outputs['model'],\n",
    "        push_destination=tfx.proto.PushDestination(filesystem=tfx.proto.PushDestination\n",
    "                                                   .Filesystem(base_directory=serving_model_dir))\n",
    "    )\n",
    "\n",
    "    components = [\n",
    "        example_gen,\n",
    "        statistics_gen,\n",
    "        schema_gen,\n",
    "        example_validator,\n",
    "        transform,\n",
    "        trainer,\n",
    "        pusher,\n",
    "    ]\n",
    "\n",
    "    return tfx.dsl.Pipeline(\n",
    "        pipeline_name=pipeline_name,\n",
    "        pipeline_root=pipeline_root,\n",
    "        metadata_connection_config=tfx.orchestration.metadata.sqlite_metadata_connection_config(metadata_path),\n",
    "        components=components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Excluding no splits because exclude_splits is not set.\n",
      "INFO:absl:Excluding no splits because exclude_splits is not set.\n",
      "INFO:absl:Excluding no splits because exclude_splits is not set.\n",
      "INFO:absl:Generating ephemeral wheel package for '/home/ekrem/Workplace/Python/tfx_seminar/iris_utils.py' (including modules: ['tfx_utils', 'iris_utils']).\n",
      "INFO:absl:User module package has hash fingerprint version 28aa14c566d301689dd39654a55b64cc2668c092535bacda4df020cf7386af6a.\n",
      "INFO:absl:Executing: ['/home/ekrem/.pyenv/versions/3.8.7/envs/tfx/bin/python3.8', '/tmp/tmpsndvzmr4/_tfx_generated_setup.py', 'bdist_wheel', '--bdist-dir', '/tmp/tmpgvlh12xt', '--dist-dir', '/tmp/tmp1txusg_0']\n",
      "/home/ekrem/.pyenv/versions/3.8.7/envs/tfx/lib/python3.8/site-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "  warnings.warn(\n",
      "INFO:absl:Successfully built user code wheel distribution at 'pipelines/iris/_wheels/tfx_user_code_Transform-0.0+28aa14c566d301689dd39654a55b64cc2668c092535bacda4df020cf7386af6a-py3-none-any.whl'; target user module is 'iris_utils'.\n",
      "INFO:absl:Full user module path is 'iris_utils@pipelines/iris/_wheels/tfx_user_code_Transform-0.0+28aa14c566d301689dd39654a55b64cc2668c092535bacda4df020cf7386af6a-py3-none-any.whl'\n",
      "INFO:absl:Generating ephemeral wheel package for '/home/ekrem/Workplace/Python/tfx_seminar/iris_utils.py' (including modules: ['tfx_utils', 'iris_utils']).\n",
      "INFO:absl:User module package has hash fingerprint version 28aa14c566d301689dd39654a55b64cc2668c092535bacda4df020cf7386af6a.\n",
      "INFO:absl:Executing: ['/home/ekrem/.pyenv/versions/3.8.7/envs/tfx/bin/python3.8', '/tmp/tmp7pptgnqy/_tfx_generated_setup.py', 'bdist_wheel', '--bdist-dir', '/tmp/tmpl0e7cucw', '--dist-dir', '/tmp/tmpqy_thzt3']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running bdist_wheel\n",
      "running build\n",
      "running build_py\n",
      "creating build\n",
      "creating build/lib\n",
      "copying tfx_utils.py -> build/lib\n",
      "copying iris_utils.py -> build/lib\n",
      "installing to /tmp/tmpgvlh12xt\n",
      "running install\n",
      "running install_lib\n",
      "copying build/lib/tfx_utils.py -> /tmp/tmpgvlh12xt\n",
      "copying build/lib/iris_utils.py -> /tmp/tmpgvlh12xt\n",
      "running install_egg_info\n",
      "running egg_info\n",
      "creating tfx_user_code_Transform.egg-info\n",
      "writing tfx_user_code_Transform.egg-info/PKG-INFO\n",
      "writing dependency_links to tfx_user_code_Transform.egg-info/dependency_links.txt\n",
      "writing top-level names to tfx_user_code_Transform.egg-info/top_level.txt\n",
      "writing manifest file 'tfx_user_code_Transform.egg-info/SOURCES.txt'\n",
      "reading manifest file 'tfx_user_code_Transform.egg-info/SOURCES.txt'\n",
      "writing manifest file 'tfx_user_code_Transform.egg-info/SOURCES.txt'\n",
      "Copying tfx_user_code_Transform.egg-info to /tmp/tmpgvlh12xt/tfx_user_code_Transform-0.0+28aa14c566d301689dd39654a55b64cc2668c092535bacda4df020cf7386af6a-py3.8.egg-info\n",
      "running install_scripts\n",
      "creating /tmp/tmpgvlh12xt/tfx_user_code_Transform-0.0+28aa14c566d301689dd39654a55b64cc2668c092535bacda4df020cf7386af6a.dist-info/WHEEL\n",
      "creating '/tmp/tmp1txusg_0/tfx_user_code_Transform-0.0+28aa14c566d301689dd39654a55b64cc2668c092535bacda4df020cf7386af6a-py3-none-any.whl' and adding '/tmp/tmpgvlh12xt' to it\n",
      "adding 'iris_utils.py'\n",
      "adding 'tfx_utils.py'\n",
      "adding 'tfx_user_code_Transform-0.0+28aa14c566d301689dd39654a55b64cc2668c092535bacda4df020cf7386af6a.dist-info/METADATA'\n",
      "adding 'tfx_user_code_Transform-0.0+28aa14c566d301689dd39654a55b64cc2668c092535bacda4df020cf7386af6a.dist-info/WHEEL'\n",
      "adding 'tfx_user_code_Transform-0.0+28aa14c566d301689dd39654a55b64cc2668c092535bacda4df020cf7386af6a.dist-info/top_level.txt'\n",
      "adding 'tfx_user_code_Transform-0.0+28aa14c566d301689dd39654a55b64cc2668c092535bacda4df020cf7386af6a.dist-info/RECORD'\n",
      "removing /tmp/tmpgvlh12xt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ekrem/.pyenv/versions/3.8.7/envs/tfx/lib/python3.8/site-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "  warnings.warn(\n",
      "INFO:absl:Successfully built user code wheel distribution at 'pipelines/iris/_wheels/tfx_user_code_Trainer-0.0+28aa14c566d301689dd39654a55b64cc2668c092535bacda4df020cf7386af6a-py3-none-any.whl'; target user module is 'iris_utils'.\n",
      "INFO:absl:Full user module path is 'iris_utils@pipelines/iris/_wheels/tfx_user_code_Trainer-0.0+28aa14c566d301689dd39654a55b64cc2668c092535bacda4df020cf7386af6a-py3-none-any.whl'\n",
      "INFO:absl:Using deployment config:\n",
      " executor_specs {\n",
      "  key: \"CsvExampleGen\"\n",
      "  value {\n",
      "    beam_executable_spec {\n",
      "      python_executor_spec {\n",
      "        class_path: \"tfx.components.example_gen.csv_example_gen.executor.Executor\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "executor_specs {\n",
      "  key: \"ExampleValidator\"\n",
      "  value {\n",
      "    python_class_executable_spec {\n",
      "      class_path: \"tfx.components.example_validator.executor.Executor\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "executor_specs {\n",
      "  key: \"Pusher\"\n",
      "  value {\n",
      "    python_class_executable_spec {\n",
      "      class_path: \"tfx.components.pusher.executor.Executor\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "executor_specs {\n",
      "  key: \"SchemaGen\"\n",
      "  value {\n",
      "    python_class_executable_spec {\n",
      "      class_path: \"tfx.components.schema_gen.executor.Executor\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "executor_specs {\n",
      "  key: \"StatisticsGen\"\n",
      "  value {\n",
      "    beam_executable_spec {\n",
      "      python_executor_spec {\n",
      "        class_path: \"tfx.components.statistics_gen.executor.Executor\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "executor_specs {\n",
      "  key: \"Trainer\"\n",
      "  value {\n",
      "    python_class_executable_spec {\n",
      "      class_path: \"tfx.components.trainer.executor.GenericExecutor\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "executor_specs {\n",
      "  key: \"Transform\"\n",
      "  value {\n",
      "    beam_executable_spec {\n",
      "      python_executor_spec {\n",
      "        class_path: \"tfx.components.transform.executor.Executor\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "custom_driver_specs {\n",
      "  key: \"CsvExampleGen\"\n",
      "  value {\n",
      "    python_class_executable_spec {\n",
      "      class_path: \"tfx.components.example_gen.driver.FileBasedDriver\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "metadata_connection_config {\n",
      "  sqlite {\n",
      "    filename_uri: \"metadata/iris/metadata.db\"\n",
      "    connection_mode: READWRITE_OPENCREATE\n",
      "  }\n",
      "}\n",
      "\n",
      "INFO:absl:Using connection config:\n",
      " sqlite {\n",
      "  filename_uri: \"metadata/iris/metadata.db\"\n",
      "  connection_mode: READWRITE_OPENCREATE\n",
      "}\n",
      "\n",
      "INFO:absl:Component CsvExampleGen is running.\n",
      "INFO:absl:Running launcher for node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.example_gen.csv_example_gen.component.CsvExampleGen\"\n",
      "  }\n",
      "  id: \"CsvExampleGen\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"iris\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2021-11-10T14:37:25.973849\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"iris.CsvExampleGen\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Examples\"\n",
      "          properties {\n",
      "            key: \"span\"\n",
      "            value: INT\n",
      "          }\n",
      "          properties {\n",
      "            key: \"split_names\"\n",
      "            value: STRING\n",
      "          }\n",
      "          properties {\n",
      "            key: \"version\"\n",
      "            value: INT\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"input_base\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"data\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"input_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"splits\\\": [\\n    {\\n      \\\"name\\\": \\\"single_split\\\",\\n      \\\"pattern\\\": \\\"*\\\"\\n    }\\n  ]\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"output_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"split_config\\\": {\\n    \\\"splits\\\": [\\n      {\\n        \\\"hash_buckets\\\": 2,\\n        \\\"name\\\": \\\"train\\\"\\n      },\\n      {\\n        \\\"hash_buckets\\\": 1,\\n        \\\"name\\\": \\\"eval\\\"\\n      }\\n    ]\\n  }\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"output_data_format\"\n",
      "    value {\n",
      "      field_value {\n",
      "        int_value: 6\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"output_file_format\"\n",
      "    value {\n",
      "      field_value {\n",
      "        int_value: 5\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "downstream_nodes: \"StatisticsGen\"\n",
      "downstream_nodes: \"Trainer\"\n",
      "downstream_nodes: \"Transform\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      "\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:select span and version = (0, None)\n",
      "INFO:absl:latest span and version = (0, None)\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Going to run a new execution 6\n",
      "INFO:absl:Going to run a new execution: ExecutionInfo(execution_id=6, input_dict={}, output_dict=defaultdict(<class 'list'>, {'examples': [Artifact(artifact: uri: \"pipelines/iris/CsvExampleGen/examples/6\"\n",
      "custom_properties {\n",
      "  key: \"input_fingerprint\"\n",
      "  value {\n",
      "    string_value: \"split:single_split,num_files:1,total_bytes:4362,xor_checksum:1636551445,sum_checksum:1636551445\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"iris:2021-11-10T14:37:25.973849:CsvExampleGen:examples:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"span\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      ", artifact_type: name: \"Examples\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value: INT\n",
      "}\n",
      ")]}), exec_properties={'output_file_format': 5, 'input_config': '{\\n  \"splits\": [\\n    {\\n      \"name\": \"single_split\",\\n      \"pattern\": \"*\"\\n    }\\n  ]\\n}', 'output_config': '{\\n  \"split_config\": {\\n    \"splits\": [\\n      {\\n        \"hash_buckets\": 2,\\n        \"name\": \"train\"\\n      },\\n      {\\n        \"hash_buckets\": 1,\\n        \"name\": \"eval\"\\n      }\\n    ]\\n  }\\n}', 'output_data_format': 6, 'input_base': 'data', 'span': 0, 'version': None, 'input_fingerprint': 'split:single_split,num_files:1,total_bytes:4362,xor_checksum:1636551445,sum_checksum:1636551445'}, execution_output_uri='pipelines/iris/CsvExampleGen/.system/executor_execution/6/executor_output.pb', stateful_working_dir='pipelines/iris/CsvExampleGen/.system/stateful_working_dir/2021-11-10T14:37:25.973849', tmp_dir='pipelines/iris/CsvExampleGen/.system/executor_execution/6/.temp/', pipeline_node=node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.example_gen.csv_example_gen.component.CsvExampleGen\"\n",
      "  }\n",
      "  id: \"CsvExampleGen\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"iris\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2021-11-10T14:37:25.973849\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"iris.CsvExampleGen\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Examples\"\n",
      "          properties {\n",
      "            key: \"span\"\n",
      "            value: INT\n",
      "          }\n",
      "          properties {\n",
      "            key: \"split_names\"\n",
      "            value: STRING\n",
      "          }\n",
      "          properties {\n",
      "            key: \"version\"\n",
      "            value: INT\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"input_base\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"data\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"input_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"splits\\\": [\\n    {\\n      \\\"name\\\": \\\"single_split\\\",\\n      \\\"pattern\\\": \\\"*\\\"\\n    }\\n  ]\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"output_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"split_config\\\": {\\n    \\\"splits\\\": [\\n      {\\n        \\\"hash_buckets\\\": 2,\\n        \\\"name\\\": \\\"train\\\"\\n      },\\n      {\\n        \\\"hash_buckets\\\": 1,\\n        \\\"name\\\": \\\"eval\\\"\\n      }\\n    ]\\n  }\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"output_data_format\"\n",
      "    value {\n",
      "      field_value {\n",
      "        int_value: 6\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"output_file_format\"\n",
      "    value {\n",
      "      field_value {\n",
      "        int_value: 5\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "downstream_nodes: \"StatisticsGen\"\n",
      "downstream_nodes: \"Trainer\"\n",
      "downstream_nodes: \"Transform\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      ", pipeline_info=id: \"iris\"\n",
      ", pipeline_run_id='2021-11-10T14:37:25.973849')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Generating examples.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running bdist_wheel\n",
      "running build\n",
      "running build_py\n",
      "creating build\n",
      "creating build/lib\n",
      "copying tfx_utils.py -> build/lib\n",
      "copying iris_utils.py -> build/lib\n",
      "installing to /tmp/tmpl0e7cucw\n",
      "running install\n",
      "running install_lib\n",
      "copying build/lib/tfx_utils.py -> /tmp/tmpl0e7cucw\n",
      "copying build/lib/iris_utils.py -> /tmp/tmpl0e7cucw\n",
      "running install_egg_info\n",
      "running egg_info\n",
      "creating tfx_user_code_Trainer.egg-info\n",
      "writing tfx_user_code_Trainer.egg-info/PKG-INFO\n",
      "writing dependency_links to tfx_user_code_Trainer.egg-info/dependency_links.txt\n",
      "writing top-level names to tfx_user_code_Trainer.egg-info/top_level.txt\n",
      "writing manifest file 'tfx_user_code_Trainer.egg-info/SOURCES.txt'\n",
      "reading manifest file 'tfx_user_code_Trainer.egg-info/SOURCES.txt'\n",
      "writing manifest file 'tfx_user_code_Trainer.egg-info/SOURCES.txt'\n",
      "Copying tfx_user_code_Trainer.egg-info to /tmp/tmpl0e7cucw/tfx_user_code_Trainer-0.0+28aa14c566d301689dd39654a55b64cc2668c092535bacda4df020cf7386af6a-py3.8.egg-info\n",
      "running install_scripts\n",
      "creating /tmp/tmpl0e7cucw/tfx_user_code_Trainer-0.0+28aa14c566d301689dd39654a55b64cc2668c092535bacda4df020cf7386af6a.dist-info/WHEEL\n",
      "creating '/tmp/tmpqy_thzt3/tfx_user_code_Trainer-0.0+28aa14c566d301689dd39654a55b64cc2668c092535bacda4df020cf7386af6a-py3-none-any.whl' and adding '/tmp/tmpl0e7cucw' to it\n",
      "adding 'iris_utils.py'\n",
      "adding 'tfx_utils.py'\n",
      "adding 'tfx_user_code_Trainer-0.0+28aa14c566d301689dd39654a55b64cc2668c092535bacda4df020cf7386af6a.dist-info/METADATA'\n",
      "adding 'tfx_user_code_Trainer-0.0+28aa14c566d301689dd39654a55b64cc2668c092535bacda4df020cf7386af6a.dist-info/WHEEL'\n",
      "adding 'tfx_user_code_Trainer-0.0+28aa14c566d301689dd39654a55b64cc2668c092535bacda4df020cf7386af6a.dist-info/top_level.txt'\n",
      "adding 'tfx_user_code_Trainer-0.0+28aa14c566d301689dd39654a55b64cc2668c092535bacda4df020cf7386af6a.dist-info/RECORD'\n",
      "removing /tmp/tmpl0e7cucw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.runners.interactive.interactive_environment:Dependencies required for Interactive Beam PCollection visualization are not available, please use: `pip install apache-beam[interactive]` to install necessary dependencies to enable all data visualization features.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (typeof window.interactive_beam_jquery == 'undefined') {\n",
       "          var jqueryScript = document.createElement('script');\n",
       "          jqueryScript.src = 'https://code.jquery.com/jquery-3.4.1.slim.min.js';\n",
       "          jqueryScript.type = 'text/javascript';\n",
       "          jqueryScript.onload = function() {\n",
       "            var datatableScript = document.createElement('script');\n",
       "            datatableScript.src = 'https://cdn.datatables.net/1.10.20/js/jquery.dataTables.min.js';\n",
       "            datatableScript.type = 'text/javascript';\n",
       "            datatableScript.onload = function() {\n",
       "              window.interactive_beam_jquery = jQuery.noConflict(true);\n",
       "              window.interactive_beam_jquery(document).ready(function($){\n",
       "                \n",
       "              });\n",
       "            }\n",
       "            document.head.appendChild(datatableScript);\n",
       "          };\n",
       "          document.head.appendChild(jqueryScript);\n",
       "        } else {\n",
       "          window.interactive_beam_jquery(document).ready(function($){\n",
       "            \n",
       "          });\n",
       "        }"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Processing input csv data data/* to TFExample.\n",
      "WARNING:root:Make sure that locally built Python SDK docker image has Python 3.8 interpreter.\n",
      "WARNING:apache_beam.io.tfrecordio:Couldn't find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\n",
      "INFO:absl:Examples generated.\n",
      "INFO:absl:Cleaning up stateless execution info.\n",
      "INFO:absl:Execution 6 succeeded.\n",
      "INFO:absl:Cleaning up stateful execution info.\n",
      "INFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'examples': [Artifact(artifact: uri: \"pipelines/iris/CsvExampleGen/examples/6\"\n",
      "custom_properties {\n",
      "  key: \"input_fingerprint\"\n",
      "  value {\n",
      "    string_value: \"split:single_split,num_files:1,total_bytes:4362,xor_checksum:1636551445,sum_checksum:1636551445\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"iris:2021-11-10T14:37:25.973849:CsvExampleGen:examples:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"span\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.3.3\"\n",
      "  }\n",
      "}\n",
      ", artifact_type: name: \"Examples\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value: INT\n",
      "}\n",
      ")]}) for execution 6\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Component CsvExampleGen is finished.\n",
      "INFO:absl:Component StatisticsGen is running.\n",
      "INFO:absl:Running launcher for node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.statistics_gen.component.StatisticsGen\"\n",
      "  }\n",
      "  id: \"StatisticsGen\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"iris\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2021-11-10T14:37:25.973849\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"iris.StatisticsGen\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"CsvExampleGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"iris\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2021-11-10T14:37:25.973849\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"iris.CsvExampleGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Examples\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"examples\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"statistics\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ExampleStatistics\"\n",
      "          properties {\n",
      "            key: \"span\"\n",
      "            value: INT\n",
      "          }\n",
      "          properties {\n",
      "            key: \"split_names\"\n",
      "            value: STRING\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"exclude_splits\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"[]\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"CsvExampleGen\"\n",
      "downstream_nodes: \"ExampleValidator\"\n",
      "downstream_nodes: \"SchemaGen\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      "\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Going to run a new execution 7\n",
      "INFO:absl:Going to run a new execution: ExecutionInfo(execution_id=7, input_dict={'examples': [Artifact(artifact: id: 5\n",
      "type_id: 15\n",
      "uri: \"pipelines/iris/CsvExampleGen/examples/6\"\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value {\n",
      "    string_value: \"[\\\"train\\\", \\\"eval\\\"]\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"file_format\"\n",
      "  value {\n",
      "    string_value: \"tfrecords_gzip\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"input_fingerprint\"\n",
      "  value {\n",
      "    string_value: \"split:single_split,num_files:1,total_bytes:4362,xor_checksum:1636551445,sum_checksum:1636551445\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"iris:2021-11-10T14:37:25.973849:CsvExampleGen:examples:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"payload_format\"\n",
      "  value {\n",
      "    string_value: \"FORMAT_TF_EXAMPLE\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"span\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.3.3\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "create_time_since_epoch: 1636551447104\n",
      "last_update_time_since_epoch: 1636551447104\n",
      ", artifact_type: id: 15\n",
      "name: \"Examples\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value: INT\n",
      "}\n",
      ")]}, output_dict=defaultdict(<class 'list'>, {'statistics': [Artifact(artifact: uri: \"pipelines/iris/StatisticsGen/statistics/7\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"iris:2021-11-10T14:37:25.973849:StatisticsGen:statistics:0\"\n",
      "  }\n",
      "}\n",
      ", artifact_type: name: \"ExampleStatistics\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      ")]}), exec_properties={'exclude_splits': '[]'}, execution_output_uri='pipelines/iris/StatisticsGen/.system/executor_execution/7/executor_output.pb', stateful_working_dir='pipelines/iris/StatisticsGen/.system/stateful_working_dir/2021-11-10T14:37:25.973849', tmp_dir='pipelines/iris/StatisticsGen/.system/executor_execution/7/.temp/', pipeline_node=node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.statistics_gen.component.StatisticsGen\"\n",
      "  }\n",
      "  id: \"StatisticsGen\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"iris\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2021-11-10T14:37:25.973849\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"iris.StatisticsGen\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"CsvExampleGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"iris\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2021-11-10T14:37:25.973849\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"iris.CsvExampleGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Examples\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"examples\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"statistics\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ExampleStatistics\"\n",
      "          properties {\n",
      "            key: \"span\"\n",
      "            value: INT\n",
      "          }\n",
      "          properties {\n",
      "            key: \"split_names\"\n",
      "            value: STRING\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"exclude_splits\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"[]\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"CsvExampleGen\"\n",
      "downstream_nodes: \"ExampleValidator\"\n",
      "downstream_nodes: \"SchemaGen\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      ", pipeline_info=id: \"iris\"\n",
      ", pipeline_run_id='2021-11-10T14:37:25.973849')\n",
      "INFO:absl:Generating statistics for split train.\n",
      "INFO:absl:Statistics for split train written to pipelines/iris/StatisticsGen/statistics/7/Split-train.\n",
      "INFO:absl:Generating statistics for split eval.\n",
      "INFO:absl:Statistics for split eval written to pipelines/iris/StatisticsGen/statistics/7/Split-eval.\n",
      "WARNING:root:Make sure that locally built Python SDK docker image has Python 3.8 interpreter.\n",
      "INFO:absl:Cleaning up stateless execution info.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Execution 7 succeeded.\n",
      "INFO:absl:Cleaning up stateful execution info.\n",
      "INFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'statistics': [Artifact(artifact: uri: \"pipelines/iris/StatisticsGen/statistics/7\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"iris:2021-11-10T14:37:25.973849:StatisticsGen:statistics:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.3.3\"\n",
      "  }\n",
      "}\n",
      ", artifact_type: name: \"ExampleStatistics\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      ")]}) for execution 7\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Component StatisticsGen is finished.\n",
      "INFO:absl:Component SchemaGen is running.\n",
      "INFO:absl:Running launcher for node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.schema_gen.component.SchemaGen\"\n",
      "  }\n",
      "  id: \"SchemaGen\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"iris\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2021-11-10T14:37:25.973849\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"iris.SchemaGen\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"statistics\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"StatisticsGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"iris\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2021-11-10T14:37:25.973849\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"iris.StatisticsGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"ExampleStatistics\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"statistics\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"schema\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Schema\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"exclude_splits\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"[]\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"infer_feature_shape\"\n",
      "    value {\n",
      "      field_value {\n",
      "        int_value: 1\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"StatisticsGen\"\n",
      "downstream_nodes: \"ExampleValidator\"\n",
      "downstream_nodes: \"Trainer\"\n",
      "downstream_nodes: \"Transform\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      "\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Going to run a new execution 8\n",
      "INFO:absl:Going to run a new execution: ExecutionInfo(execution_id=8, input_dict={'statistics': [Artifact(artifact: id: 6\n",
      "type_id: 17\n",
      "uri: \"pipelines/iris/StatisticsGen/statistics/7\"\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value {\n",
      "    string_value: \"[\\\"train\\\", \\\"eval\\\"]\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"iris:2021-11-10T14:37:25.973849:StatisticsGen:statistics:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.3.3\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "create_time_since_epoch: 1636551449041\n",
      "last_update_time_since_epoch: 1636551449041\n",
      ", artifact_type: id: 17\n",
      "name: \"ExampleStatistics\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      ")]}, output_dict=defaultdict(<class 'list'>, {'schema': [Artifact(artifact: uri: \"pipelines/iris/SchemaGen/schema/8\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"iris:2021-11-10T14:37:25.973849:SchemaGen:schema:0\"\n",
      "  }\n",
      "}\n",
      ", artifact_type: name: \"Schema\"\n",
      ")]}), exec_properties={'infer_feature_shape': 1, 'exclude_splits': '[]'}, execution_output_uri='pipelines/iris/SchemaGen/.system/executor_execution/8/executor_output.pb', stateful_working_dir='pipelines/iris/SchemaGen/.system/stateful_working_dir/2021-11-10T14:37:25.973849', tmp_dir='pipelines/iris/SchemaGen/.system/executor_execution/8/.temp/', pipeline_node=node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.schema_gen.component.SchemaGen\"\n",
      "  }\n",
      "  id: \"SchemaGen\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"iris\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2021-11-10T14:37:25.973849\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"iris.SchemaGen\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"statistics\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"StatisticsGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"iris\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2021-11-10T14:37:25.973849\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"iris.StatisticsGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"ExampleStatistics\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"statistics\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"schema\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Schema\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"exclude_splits\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"[]\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"infer_feature_shape\"\n",
      "    value {\n",
      "      field_value {\n",
      "        int_value: 1\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"StatisticsGen\"\n",
      "downstream_nodes: \"ExampleValidator\"\n",
      "downstream_nodes: \"Trainer\"\n",
      "downstream_nodes: \"Transform\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      ", pipeline_info=id: \"iris\"\n",
      ", pipeline_run_id='2021-11-10T14:37:25.973849')\n",
      "INFO:absl:Processing schema from statistics for split train.\n",
      "INFO:absl:Processing schema from statistics for split eval.\n",
      "INFO:absl:Schema written to pipelines/iris/SchemaGen/schema/8/schema.pbtxt.\n",
      "INFO:absl:Cleaning up stateless execution info.\n",
      "INFO:absl:Execution 8 succeeded.\n",
      "INFO:absl:Cleaning up stateful execution info.\n",
      "INFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'schema': [Artifact(artifact: uri: \"pipelines/iris/SchemaGen/schema/8\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"iris:2021-11-10T14:37:25.973849:SchemaGen:schema:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.3.3\"\n",
      "  }\n",
      "}\n",
      ", artifact_type: name: \"Schema\"\n",
      ")]}) for execution 8\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Component SchemaGen is finished.\n",
      "INFO:absl:Component ExampleValidator is running.\n",
      "INFO:absl:Running launcher for node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.example_validator.component.ExampleValidator\"\n",
      "  }\n",
      "  id: \"ExampleValidator\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"iris\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2021-11-10T14:37:25.973849\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"iris.ExampleValidator\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"schema\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"SchemaGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"iris\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2021-11-10T14:37:25.973849\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"iris.SchemaGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Schema\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"schema\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"statistics\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"StatisticsGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"iris\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2021-11-10T14:37:25.973849\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"iris.StatisticsGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"ExampleStatistics\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"statistics\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"anomalies\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ExampleAnomalies\"\n",
      "          properties {\n",
      "            key: \"span\"\n",
      "            value: INT\n",
      "          }\n",
      "          properties {\n",
      "            key: \"split_names\"\n",
      "            value: STRING\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"exclude_splits\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"[]\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"SchemaGen\"\n",
      "upstream_nodes: \"StatisticsGen\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Going to run a new execution 9\n",
      "INFO:absl:Going to run a new execution: ExecutionInfo(execution_id=9, input_dict={'schema': [Artifact(artifact: id: 7\n",
      "type_id: 19\n",
      "uri: \"pipelines/iris/SchemaGen/schema/8\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"iris:2021-11-10T14:37:25.973849:SchemaGen:schema:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.3.3\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "create_time_since_epoch: 1636551449093\n",
      "last_update_time_since_epoch: 1636551449093\n",
      ", artifact_type: id: 19\n",
      "name: \"Schema\"\n",
      ")], 'statistics': [Artifact(artifact: id: 6\n",
      "type_id: 17\n",
      "uri: \"pipelines/iris/StatisticsGen/statistics/7\"\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value {\n",
      "    string_value: \"[\\\"train\\\", \\\"eval\\\"]\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"iris:2021-11-10T14:37:25.973849:StatisticsGen:statistics:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.3.3\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "create_time_since_epoch: 1636551449041\n",
      "last_update_time_since_epoch: 1636551449041\n",
      ", artifact_type: id: 17\n",
      "name: \"ExampleStatistics\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      ")]}, output_dict=defaultdict(<class 'list'>, {'anomalies': [Artifact(artifact: uri: \"pipelines/iris/ExampleValidator/anomalies/9\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"iris:2021-11-10T14:37:25.973849:ExampleValidator:anomalies:0\"\n",
      "  }\n",
      "}\n",
      ", artifact_type: name: \"ExampleAnomalies\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      ")]}), exec_properties={'exclude_splits': '[]'}, execution_output_uri='pipelines/iris/ExampleValidator/.system/executor_execution/9/executor_output.pb', stateful_working_dir='pipelines/iris/ExampleValidator/.system/stateful_working_dir/2021-11-10T14:37:25.973849', tmp_dir='pipelines/iris/ExampleValidator/.system/executor_execution/9/.temp/', pipeline_node=node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.example_validator.component.ExampleValidator\"\n",
      "  }\n",
      "  id: \"ExampleValidator\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"iris\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2021-11-10T14:37:25.973849\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"iris.ExampleValidator\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"schema\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"SchemaGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"iris\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2021-11-10T14:37:25.973849\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"iris.SchemaGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Schema\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"schema\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"statistics\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"StatisticsGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"iris\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2021-11-10T14:37:25.973849\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"iris.StatisticsGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"ExampleStatistics\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"statistics\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"anomalies\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ExampleAnomalies\"\n",
      "          properties {\n",
      "            key: \"span\"\n",
      "            value: INT\n",
      "          }\n",
      "          properties {\n",
      "            key: \"split_names\"\n",
      "            value: STRING\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"exclude_splits\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"[]\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"SchemaGen\"\n",
      "upstream_nodes: \"StatisticsGen\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      ", pipeline_info=id: \"iris\"\n",
      ", pipeline_run_id='2021-11-10T14:37:25.973849')\n",
      "INFO:absl:Validating schema against the computed statistics for split train.\n",
      "INFO:absl:Validation complete for split train. Anomalies written to pipelines/iris/ExampleValidator/anomalies/9/Split-train.\n",
      "INFO:absl:Validating schema against the computed statistics for split eval.\n",
      "INFO:absl:Validation complete for split eval. Anomalies written to pipelines/iris/ExampleValidator/anomalies/9/Split-eval.\n",
      "INFO:absl:Cleaning up stateless execution info.\n",
      "INFO:absl:Execution 9 succeeded.\n",
      "INFO:absl:Cleaning up stateful execution info.\n",
      "INFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'anomalies': [Artifact(artifact: uri: \"pipelines/iris/ExampleValidator/anomalies/9\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"iris:2021-11-10T14:37:25.973849:ExampleValidator:anomalies:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.3.3\"\n",
      "  }\n",
      "}\n",
      ", artifact_type: name: \"ExampleAnomalies\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      ")]}) for execution 9\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Component ExampleValidator is finished.\n",
      "INFO:absl:Component Transform is running.\n",
      "INFO:absl:Running launcher for node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.transform.component.Transform\"\n",
      "  }\n",
      "  id: \"Transform\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"iris\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2021-11-10T14:37:25.973849\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"iris.Transform\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"CsvExampleGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"iris\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2021-11-10T14:37:25.973849\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"iris.CsvExampleGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Examples\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"examples\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"schema\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"SchemaGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"iris\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2021-11-10T14:37:25.973849\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"iris.SchemaGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Schema\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"schema\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"post_transform_anomalies\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ExampleAnomalies\"\n",
      "          properties {\n",
      "            key: \"span\"\n",
      "            value: INT\n",
      "          }\n",
      "          properties {\n",
      "            key: \"split_names\"\n",
      "            value: STRING\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"post_transform_schema\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Schema\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"post_transform_stats\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ExampleStatistics\"\n",
      "          properties {\n",
      "            key: \"span\"\n",
      "            value: INT\n",
      "          }\n",
      "          properties {\n",
      "            key: \"split_names\"\n",
      "            value: STRING\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"pre_transform_schema\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Schema\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"pre_transform_stats\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ExampleStatistics\"\n",
      "          properties {\n",
      "            key: \"span\"\n",
      "            value: INT\n",
      "          }\n",
      "          properties {\n",
      "            key: \"split_names\"\n",
      "            value: STRING\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"transform_graph\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"TransformGraph\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"updated_analyzer_cache\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"TransformCache\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"custom_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"null\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"disable_statistics\"\n",
      "    value {\n",
      "      field_value {\n",
      "        int_value: 0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"force_tf_compat_v1\"\n",
      "    value {\n",
      "      field_value {\n",
      "        int_value: 0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"module_path\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"iris_utils@pipelines/iris/_wheels/tfx_user_code_Transform-0.0+28aa14c566d301689dd39654a55b64cc2668c092535bacda4df020cf7386af6a-py3-none-any.whl\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"CsvExampleGen\"\n",
      "upstream_nodes: \"SchemaGen\"\n",
      "downstream_nodes: \"Trainer\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "I1110 14:37:29.179325 17837 rdbms_metadata_access_object.cc:686] No property is defined for the Type\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Going to run a new execution 10\n",
      "INFO:absl:Going to run a new execution: ExecutionInfo(execution_id=10, input_dict={'schema': [Artifact(artifact: id: 7\n",
      "type_id: 19\n",
      "uri: \"pipelines/iris/SchemaGen/schema/8\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"iris:2021-11-10T14:37:25.973849:SchemaGen:schema:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.3.3\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "create_time_since_epoch: 1636551449093\n",
      "last_update_time_since_epoch: 1636551449093\n",
      ", artifact_type: id: 19\n",
      "name: \"Schema\"\n",
      ")], 'examples': [Artifact(artifact: id: 5\n",
      "type_id: 15\n",
      "uri: \"pipelines/iris/CsvExampleGen/examples/6\"\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value {\n",
      "    string_value: \"[\\\"train\\\", \\\"eval\\\"]\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"file_format\"\n",
      "  value {\n",
      "    string_value: \"tfrecords_gzip\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"input_fingerprint\"\n",
      "  value {\n",
      "    string_value: \"split:single_split,num_files:1,total_bytes:4362,xor_checksum:1636551445,sum_checksum:1636551445\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"iris:2021-11-10T14:37:25.973849:CsvExampleGen:examples:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"payload_format\"\n",
      "  value {\n",
      "    string_value: \"FORMAT_TF_EXAMPLE\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"span\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.3.3\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "create_time_since_epoch: 1636551447104\n",
      "last_update_time_since_epoch: 1636551447104\n",
      ", artifact_type: id: 15\n",
      "name: \"Examples\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value: INT\n",
      "}\n",
      ")]}, output_dict=defaultdict(<class 'list'>, {'post_transform_stats': [Artifact(artifact: uri: \"pipelines/iris/Transform/post_transform_stats/10\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"iris:2021-11-10T14:37:25.973849:Transform:post_transform_stats:0\"\n",
      "  }\n",
      "}\n",
      ", artifact_type: name: \"ExampleStatistics\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      ")], 'pre_transform_stats': [Artifact(artifact: uri: \"pipelines/iris/Transform/pre_transform_stats/10\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"iris:2021-11-10T14:37:25.973849:Transform:pre_transform_stats:0\"\n",
      "  }\n",
      "}\n",
      ", artifact_type: name: \"ExampleStatistics\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      ")], 'pre_transform_schema': [Artifact(artifact: uri: \"pipelines/iris/Transform/pre_transform_schema/10\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"iris:2021-11-10T14:37:25.973849:Transform:pre_transform_schema:0\"\n",
      "  }\n",
      "}\n",
      ", artifact_type: name: \"Schema\"\n",
      ")], 'transform_graph': [Artifact(artifact: uri: \"pipelines/iris/Transform/transform_graph/10\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"iris:2021-11-10T14:37:25.973849:Transform:transform_graph:0\"\n",
      "  }\n",
      "}\n",
      ", artifact_type: name: \"TransformGraph\"\n",
      ")], 'post_transform_anomalies': [Artifact(artifact: uri: \"pipelines/iris/Transform/post_transform_anomalies/10\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"iris:2021-11-10T14:37:25.973849:Transform:post_transform_anomalies:0\"\n",
      "  }\n",
      "}\n",
      ", artifact_type: name: \"ExampleAnomalies\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      ")], 'post_transform_schema': [Artifact(artifact: uri: \"pipelines/iris/Transform/post_transform_schema/10\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"iris:2021-11-10T14:37:25.973849:Transform:post_transform_schema:0\"\n",
      "  }\n",
      "}\n",
      ", artifact_type: name: \"Schema\"\n",
      ")], 'updated_analyzer_cache': [Artifact(artifact: uri: \"pipelines/iris/Transform/updated_analyzer_cache/10\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"iris:2021-11-10T14:37:25.973849:Transform:updated_analyzer_cache:0\"\n",
      "  }\n",
      "}\n",
      ", artifact_type: name: \"TransformCache\"\n",
      ")]}), exec_properties={'custom_config': 'null', 'force_tf_compat_v1': 0, 'module_path': 'iris_utils@pipelines/iris/_wheels/tfx_user_code_Transform-0.0+28aa14c566d301689dd39654a55b64cc2668c092535bacda4df020cf7386af6a-py3-none-any.whl', 'disable_statistics': 0}, execution_output_uri='pipelines/iris/Transform/.system/executor_execution/10/executor_output.pb', stateful_working_dir='pipelines/iris/Transform/.system/stateful_working_dir/2021-11-10T14:37:25.973849', tmp_dir='pipelines/iris/Transform/.system/executor_execution/10/.temp/', pipeline_node=node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.transform.component.Transform\"\n",
      "  }\n",
      "  id: \"Transform\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"iris\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2021-11-10T14:37:25.973849\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"iris.Transform\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"CsvExampleGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"iris\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2021-11-10T14:37:25.973849\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"iris.CsvExampleGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Examples\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"examples\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"schema\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"SchemaGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"iris\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2021-11-10T14:37:25.973849\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"iris.SchemaGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Schema\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"schema\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"post_transform_anomalies\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ExampleAnomalies\"\n",
      "          properties {\n",
      "            key: \"span\"\n",
      "            value: INT\n",
      "          }\n",
      "          properties {\n",
      "            key: \"split_names\"\n",
      "            value: STRING\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"post_transform_schema\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Schema\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"post_transform_stats\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ExampleStatistics\"\n",
      "          properties {\n",
      "            key: \"span\"\n",
      "            value: INT\n",
      "          }\n",
      "          properties {\n",
      "            key: \"split_names\"\n",
      "            value: STRING\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"pre_transform_schema\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Schema\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"pre_transform_stats\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ExampleStatistics\"\n",
      "          properties {\n",
      "            key: \"span\"\n",
      "            value: INT\n",
      "          }\n",
      "          properties {\n",
      "            key: \"split_names\"\n",
      "            value: STRING\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"transform_graph\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"TransformGraph\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"updated_analyzer_cache\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"TransformCache\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"custom_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"null\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"disable_statistics\"\n",
      "    value {\n",
      "      field_value {\n",
      "        int_value: 0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"force_tf_compat_v1\"\n",
      "    value {\n",
      "      field_value {\n",
      "        int_value: 0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"module_path\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"iris_utils@pipelines/iris/_wheels/tfx_user_code_Transform-0.0+28aa14c566d301689dd39654a55b64cc2668c092535bacda4df020cf7386af6a-py3-none-any.whl\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"CsvExampleGen\"\n",
      "upstream_nodes: \"SchemaGen\"\n",
      "downstream_nodes: \"Trainer\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      ", pipeline_info=id: \"iris\"\n",
      ", pipeline_run_id='2021-11-10T14:37:25.973849')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Analyze the 'train' split and transform all splits when splits_config is not set.\n",
      "INFO:absl:udf_utils.get_fn {'module_file': None, 'module_path': 'iris_utils@pipelines/iris/_wheels/tfx_user_code_Transform-0.0+28aa14c566d301689dd39654a55b64cc2668c092535bacda4df020cf7386af6a-py3-none-any.whl', 'preprocessing_fn': None} 'preprocessing_fn'\n",
      "INFO:absl:Installing 'pipelines/iris/_wheels/tfx_user_code_Transform-0.0+28aa14c566d301689dd39654a55b64cc2668c092535bacda4df020cf7386af6a-py3-none-any.whl' to a temporary directory.\n",
      "INFO:absl:Executing: ['/home/ekrem/.pyenv/versions/3.8.7/envs/tfx/bin/python3.8', '-m', 'pip', 'install', '--target', '/tmp/tmpdfutn0pl', 'pipelines/iris/_wheels/tfx_user_code_Transform-0.0+28aa14c566d301689dd39654a55b64cc2668c092535bacda4df020cf7386af6a-py3-none-any.whl']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./pipelines/iris/_wheels/tfx_user_code_Transform-0.0+28aa14c566d301689dd39654a55b64cc2668c092535bacda4df020cf7386af6a-py3-none-any.whl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Successfully installed 'pipelines/iris/_wheels/tfx_user_code_Transform-0.0+28aa14c566d301689dd39654a55b64cc2668c092535bacda4df020cf7386af6a-py3-none-any.whl'.\n",
      "INFO:absl:udf_utils.get_fn {'module_file': None, 'module_path': 'iris_utils@pipelines/iris/_wheels/tfx_user_code_Transform-0.0+28aa14c566d301689dd39654a55b64cc2668c092535bacda4df020cf7386af6a-py3-none-any.whl', 'stats_options_updater_fn': None} 'stats_options_updater_fn'\n",
      "INFO:absl:Installing 'pipelines/iris/_wheels/tfx_user_code_Transform-0.0+28aa14c566d301689dd39654a55b64cc2668c092535bacda4df020cf7386af6a-py3-none-any.whl' to a temporary directory.\n",
      "INFO:absl:Executing: ['/home/ekrem/.pyenv/versions/3.8.7/envs/tfx/bin/python3.8', '-m', 'pip', 'install', '--target', '/tmp/tmp72b7cjqm', 'pipelines/iris/_wheels/tfx_user_code_Transform-0.0+28aa14c566d301689dd39654a55b64cc2668c092535bacda4df020cf7386af6a-py3-none-any.whl']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: tfx-user-code-Transform\n",
      "Successfully installed tfx-user-code-Transform-0.0+28aa14c566d301689dd39654a55b64cc2668c092535bacda4df020cf7386af6a\n",
      "Processing ./pipelines/iris/_wheels/tfx_user_code_Transform-0.0+28aa14c566d301689dd39654a55b64cc2668c092535bacda4df020cf7386af6a-py3-none-any.whl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Successfully installed 'pipelines/iris/_wheels/tfx_user_code_Transform-0.0+28aa14c566d301689dd39654a55b64cc2668c092535bacda4df020cf7386af6a-py3-none-any.whl'.\n",
      "INFO:absl:Feature Species has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature Petal.Length has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature Petal.Width has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature Sepal.Length has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature Sepal.Width has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature id has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: tfx-user-code-Transform\n",
      "Successfully installed tfx-user-code-Transform-0.0+28aa14c566d301689dd39654a55b64cc2668c092535bacda4df020cf7386af6a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-10 14:37:32.097634: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ekrem/.pyenv/versions/3.8.7/envs/tfx/lib/python3.8/site-packages/tensorflow_transform/tf_utils.py:261: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use ref() instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-10 14:37:32.135341: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-10 14:37:32.135796: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-10 14:37:32.136842: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-10 14:37:32.137848: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-10 14:37:32.138308: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-10 14:37:32.138544: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-10 14:37:32.550821: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-10 14:37:32.551091: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-10 14:37:32.551317: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-10 14:37:32.551525: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1837 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "WARNING:tensorflow:From /home/ekrem/.pyenv/versions/3.8.7/envs/tfx/lib/python3.8/site-packages/tensorflow_transform/tf_utils.py:261: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use ref() instead.\n",
      "INFO:absl:Feature Species has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature Petal.Length has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature Petal.Width has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature Sepal.Length has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature Sepal.Width has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature id has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature Species has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature Petal.Length has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature Petal.Width has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature Sepal.Length has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature Sepal.Width has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature id has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature Species has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature Petal.Length has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature Petal.Width has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature Sepal.Length has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature Sepal.Width has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature id has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature Species has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature Petal.Length has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature Petal.Width has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature Sepal.Length has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature Sepal.Width has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature id has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature Species has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature Petal.Length has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature Petal.Width has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature Sepal.Length has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature Sepal.Width has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature id has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Installing 'pipelines/iris/_wheels/tfx_user_code_Transform-0.0+28aa14c566d301689dd39654a55b64cc2668c092535bacda4df020cf7386af6a-py3-none-any.whl' to a temporary directory.\n",
      "INFO:absl:Executing: ['/home/ekrem/.pyenv/versions/3.8.7/envs/tfx/bin/python3.8', '-m', 'pip', 'install', '--target', '/tmp/tmp13tf3he4', 'pipelines/iris/_wheels/tfx_user_code_Transform-0.0+28aa14c566d301689dd39654a55b64cc2668c092535bacda4df020cf7386af6a-py3-none-any.whl']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./pipelines/iris/_wheels/tfx_user_code_Transform-0.0+28aa14c566d301689dd39654a55b64cc2668c092535bacda4df020cf7386af6a-py3-none-any.whl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Successfully installed 'pipelines/iris/_wheels/tfx_user_code_Transform-0.0+28aa14c566d301689dd39654a55b64cc2668c092535bacda4df020cf7386af6a-py3-none-any.whl'.\n",
      "WARNING:root:This output type hint will be ignored and not used for type-checking purposes. Typically, output type hints for a PTransform are single (or nested) types wrapped by a PCollection, PDone, or None. Got: Tuple[Dict[str, Union[NoneType, _Dataset]], Union[Dict[str, Dict[str, PCollection]], NoneType], int] instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: tfx-user-code-Transform\n",
      "Successfully installed tfx-user-code-Transform-0.0+28aa14c566d301689dd39654a55b64cc2668c092535bacda4df020cf7386af6a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: key_value_init/LookupTableImportV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: key_value_init/LookupTableImportV2\n",
      "WARNING:root:This output type hint will be ignored and not used for type-checking purposes. Typically, output type hints for a PTransform are single (or nested) types wrapped by a PCollection, PDone, or None. Got: Tuple[Dict[str, Union[NoneType, _Dataset]], Union[Dict[str, Dict[str, PCollection]], NoneType], int] instead.\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: key_value_init/LookupTableImportV2\n",
      "2021-11-10 14:37:35.090436: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "INFO:absl:Feature Species has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature Petal.Length has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature Petal.Width has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature Sepal.Length has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature Sepal.Width has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature id has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature Species has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature Petal.Length has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature Petal.Width has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature Sepal.Length has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature Sepal.Width has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature id has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "WARNING:root:Make sure that locally built Python SDK docker image has Python 3.8 interpreter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: pipelines/iris/Transform/transform_graph/10/.temp_path/tftransform_tmp/49e736e4167a477990adf74122501b2e/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-10 14:37:37.977225: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "INFO:tensorflow:Assets written to: pipelines/iris/Transform/transform_graph/10/.temp_path/tftransform_tmp/49e736e4167a477990adf74122501b2e/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_text is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_text is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:struct2tensor is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:struct2tensor is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: pipelines/iris/Transform/transform_graph/10/.temp_path/tftransform_tmp/afc29e37215747c29fe8e7daa97796e4/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: pipelines/iris/Transform/transform_graph/10/.temp_path/tftransform_tmp/afc29e37215747c29fe8e7daa97796e4/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_text is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_text is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:struct2tensor is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:struct2tensor is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_text is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_text is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:struct2tensor is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:struct2tensor is not available.\n",
      "INFO:absl:Cleaning up stateless execution info.\n",
      "INFO:absl:Execution 10 succeeded.\n",
      "INFO:absl:Cleaning up stateful execution info.\n",
      "INFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'post_transform_stats': [Artifact(artifact: uri: \"pipelines/iris/Transform/post_transform_stats/10\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"iris:2021-11-10T14:37:25.973849:Transform:post_transform_stats:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.3.3\"\n",
      "  }\n",
      "}\n",
      ", artifact_type: name: \"ExampleStatistics\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      ")], 'pre_transform_stats': [Artifact(artifact: uri: \"pipelines/iris/Transform/pre_transform_stats/10\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"iris:2021-11-10T14:37:25.973849:Transform:pre_transform_stats:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.3.3\"\n",
      "  }\n",
      "}\n",
      ", artifact_type: name: \"ExampleStatistics\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      ")], 'pre_transform_schema': [Artifact(artifact: uri: \"pipelines/iris/Transform/pre_transform_schema/10\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"iris:2021-11-10T14:37:25.973849:Transform:pre_transform_schema:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.3.3\"\n",
      "  }\n",
      "}\n",
      ", artifact_type: name: \"Schema\"\n",
      ")], 'transform_graph': [Artifact(artifact: uri: \"pipelines/iris/Transform/transform_graph/10\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"iris:2021-11-10T14:37:25.973849:Transform:transform_graph:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.3.3\"\n",
      "  }\n",
      "}\n",
      ", artifact_type: name: \"TransformGraph\"\n",
      ")], 'post_transform_anomalies': [Artifact(artifact: uri: \"pipelines/iris/Transform/post_transform_anomalies/10\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"iris:2021-11-10T14:37:25.973849:Transform:post_transform_anomalies:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.3.3\"\n",
      "  }\n",
      "}\n",
      ", artifact_type: name: \"ExampleAnomalies\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      ")], 'post_transform_schema': [Artifact(artifact: uri: \"pipelines/iris/Transform/post_transform_schema/10\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"iris:2021-11-10T14:37:25.973849:Transform:post_transform_schema:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.3.3\"\n",
      "  }\n",
      "}\n",
      ", artifact_type: name: \"Schema\"\n",
      ")], 'updated_analyzer_cache': [Artifact(artifact: uri: \"pipelines/iris/Transform/updated_analyzer_cache/10\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"iris:2021-11-10T14:37:25.973849:Transform:updated_analyzer_cache:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.3.3\"\n",
      "  }\n",
      "}\n",
      ", artifact_type: name: \"TransformCache\"\n",
      ")]}) for execution 10\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "I1110 14:37:41.328918 17837 rdbms_metadata_access_object.cc:686] No property is defined for the Type\n",
      "I1110 14:37:41.344801 17837 rdbms_metadata_access_object.cc:686] No property is defined for the Type\n",
      "INFO:absl:Component Transform is finished.\n",
      "INFO:absl:Component Trainer is running.\n",
      "INFO:absl:Running launcher for node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.trainer.component.Trainer\"\n",
      "  }\n",
      "  id: \"Trainer\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"iris\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2021-11-10T14:37:25.973849\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"iris.Trainer\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"CsvExampleGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"iris\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2021-11-10T14:37:25.973849\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"iris.CsvExampleGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Examples\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"examples\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"schema\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"SchemaGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"iris\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2021-11-10T14:37:25.973849\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"iris.SchemaGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Schema\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"schema\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"transform_graph\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"Transform\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"iris\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2021-11-10T14:37:25.973849\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"iris.Transform\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"TransformGraph\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"transform_graph\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"model\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Model\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"model_run\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ModelRun\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"custom_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"null\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"eval_args\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"num_steps\\\": 5\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"module_path\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"iris_utils@pipelines/iris/_wheels/tfx_user_code_Trainer-0.0+28aa14c566d301689dd39654a55b64cc2668c092535bacda4df020cf7386af6a-py3-none-any.whl\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"train_args\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"num_steps\\\": 2000\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"CsvExampleGen\"\n",
      "upstream_nodes: \"SchemaGen\"\n",
      "upstream_nodes: \"Transform\"\n",
      "downstream_nodes: \"Pusher\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      "\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Going to run a new execution 11\n",
      "INFO:absl:Going to run a new execution: ExecutionInfo(execution_id=11, input_dict={'examples': [Artifact(artifact: id: 5\n",
      "type_id: 15\n",
      "uri: \"pipelines/iris/CsvExampleGen/examples/6\"\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value {\n",
      "    string_value: \"[\\\"train\\\", \\\"eval\\\"]\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"file_format\"\n",
      "  value {\n",
      "    string_value: \"tfrecords_gzip\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"input_fingerprint\"\n",
      "  value {\n",
      "    string_value: \"split:single_split,num_files:1,total_bytes:4362,xor_checksum:1636551445,sum_checksum:1636551445\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"iris:2021-11-10T14:37:25.973849:CsvExampleGen:examples:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"payload_format\"\n",
      "  value {\n",
      "    string_value: \"FORMAT_TF_EXAMPLE\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"span\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.3.3\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "create_time_since_epoch: 1636551447104\n",
      "last_update_time_since_epoch: 1636551447104\n",
      ", artifact_type: id: 15\n",
      "name: \"Examples\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value: INT\n",
      "}\n",
      ")], 'transform_graph': [Artifact(artifact: id: 12\n",
      "type_id: 24\n",
      "uri: \"pipelines/iris/Transform/transform_graph/10\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"iris:2021-11-10T14:37:25.973849:Transform:transform_graph:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.3.3\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "create_time_since_epoch: 1636551461353\n",
      "last_update_time_since_epoch: 1636551461353\n",
      ", artifact_type: id: 24\n",
      "name: \"TransformGraph\"\n",
      ")], 'schema': [Artifact(artifact: id: 7\n",
      "type_id: 19\n",
      "uri: \"pipelines/iris/SchemaGen/schema/8\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"iris:2021-11-10T14:37:25.973849:SchemaGen:schema:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.3.3\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "create_time_since_epoch: 1636551449093\n",
      "last_update_time_since_epoch: 1636551449093\n",
      ", artifact_type: id: 19\n",
      "name: \"Schema\"\n",
      ")]}, output_dict=defaultdict(<class 'list'>, {'model_run': [Artifact(artifact: uri: \"pipelines/iris/Trainer/model_run/11\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"iris:2021-11-10T14:37:25.973849:Trainer:model_run:0\"\n",
      "  }\n",
      "}\n",
      ", artifact_type: name: \"ModelRun\"\n",
      ")], 'model': [Artifact(artifact: uri: \"pipelines/iris/Trainer/model/11\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"iris:2021-11-10T14:37:25.973849:Trainer:model:0\"\n",
      "  }\n",
      "}\n",
      ", artifact_type: name: \"Model\"\n",
      ")]}), exec_properties={'train_args': '{\\n  \"num_steps\": 2000\\n}', 'eval_args': '{\\n  \"num_steps\": 5\\n}', 'custom_config': 'null', 'module_path': 'iris_utils@pipelines/iris/_wheels/tfx_user_code_Trainer-0.0+28aa14c566d301689dd39654a55b64cc2668c092535bacda4df020cf7386af6a-py3-none-any.whl'}, execution_output_uri='pipelines/iris/Trainer/.system/executor_execution/11/executor_output.pb', stateful_working_dir='pipelines/iris/Trainer/.system/stateful_working_dir/2021-11-10T14:37:25.973849', tmp_dir='pipelines/iris/Trainer/.system/executor_execution/11/.temp/', pipeline_node=node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.trainer.component.Trainer\"\n",
      "  }\n",
      "  id: \"Trainer\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"iris\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2021-11-10T14:37:25.973849\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"iris.Trainer\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"CsvExampleGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"iris\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2021-11-10T14:37:25.973849\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"iris.CsvExampleGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Examples\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"examples\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"schema\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"SchemaGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"iris\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2021-11-10T14:37:25.973849\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"iris.SchemaGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Schema\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"schema\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"transform_graph\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"Transform\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"iris\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2021-11-10T14:37:25.973849\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"iris.Transform\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"TransformGraph\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"transform_graph\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"model\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Model\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"model_run\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ModelRun\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"custom_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"null\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"eval_args\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"num_steps\\\": 5\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"module_path\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"iris_utils@pipelines/iris/_wheels/tfx_user_code_Trainer-0.0+28aa14c566d301689dd39654a55b64cc2668c092535bacda4df020cf7386af6a-py3-none-any.whl\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"train_args\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"num_steps\\\": 2000\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"CsvExampleGen\"\n",
      "upstream_nodes: \"SchemaGen\"\n",
      "upstream_nodes: \"Transform\"\n",
      "downstream_nodes: \"Pusher\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      ", pipeline_info=id: \"iris\"\n",
      ", pipeline_run_id='2021-11-10T14:37:25.973849')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Train on the 'train' split when train_args.splits is not set.\n",
      "INFO:absl:Evaluate on the 'eval' split when eval_args.splits is not set.\n",
      "INFO:absl:udf_utils.get_fn {'train_args': '{\\n  \"num_steps\": 2000\\n}', 'eval_args': '{\\n  \"num_steps\": 5\\n}', 'custom_config': 'null', 'module_path': 'iris_utils@pipelines/iris/_wheels/tfx_user_code_Trainer-0.0+28aa14c566d301689dd39654a55b64cc2668c092535bacda4df020cf7386af6a-py3-none-any.whl'} 'run_fn'\n",
      "INFO:absl:Installing 'pipelines/iris/_wheels/tfx_user_code_Trainer-0.0+28aa14c566d301689dd39654a55b64cc2668c092535bacda4df020cf7386af6a-py3-none-any.whl' to a temporary directory.\n",
      "INFO:absl:Executing: ['/home/ekrem/.pyenv/versions/3.8.7/envs/tfx/bin/python3.8', '-m', 'pip', 'install', '--target', '/tmp/tmpe5dcqf2y', 'pipelines/iris/_wheels/tfx_user_code_Trainer-0.0+28aa14c566d301689dd39654a55b64cc2668c092535bacda4df020cf7386af6a-py3-none-any.whl']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./pipelines/iris/_wheels/tfx_user_code_Trainer-0.0+28aa14c566d301689dd39654a55b64cc2668c092535bacda4df020cf7386af6a-py3-none-any.whl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Successfully installed 'pipelines/iris/_wheels/tfx_user_code_Trainer-0.0+28aa14c566d301689dd39654a55b64cc2668c092535bacda4df020cf7386af6a-py3-none-any.whl'.\n",
      "INFO:absl:Training model.\n",
      "INFO:absl:Feature Species has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature Petal.Length has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature Petal.Width has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature Sepal.Length has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature Sepal.Width has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature id has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: tfx-user-code-Trainer\n",
      "Successfully installed tfx-user-code-Trainer-0.0+28aa14c566d301689dd39654a55b64cc2668c092535bacda4df020cf7386af6a\n",
      "INFO:tensorflow:tensorflow_text is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_text is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:struct2tensor is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:struct2tensor is not available.\n",
      "INFO:absl:Feature Species has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature Petal.Length has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature Petal.Width has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature Sepal.Length has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature Sepal.Width has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature id has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "2021-11-10 14:37:43.709372: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
      "2021-11-10 14:37:43.709405: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n",
      "2021-11-10 14:37:43.716999: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1614] Profiler found 1 GPUs\n",
      "2021-11-10 14:37:43.992592: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n",
      "2021-11-10 14:37:43.994411: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1748] CUPTI activity buffer flushed\n",
      "INFO:absl:Model: \"model\"\n",
      "INFO:absl:__________________________________________________________________________________________________\n",
      "INFO:absl:Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "INFO:absl:==================================================================================================\n",
      "INFO:absl:Sepal.Length_xf (InputLayer)    [(None, 1)]          0                                            \n",
      "INFO:absl:__________________________________________________________________________________________________\n",
      "INFO:absl:Sepal.Width_xf (InputLayer)     [(None, 1)]          0                                            \n",
      "INFO:absl:__________________________________________________________________________________________________\n",
      "INFO:absl:Petal.Length_xf (InputLayer)    [(None, 1)]          0                                            \n",
      "INFO:absl:__________________________________________________________________________________________________\n",
      "INFO:absl:Petal.Width_xf (InputLayer)     [(None, 1)]          0                                            \n",
      "INFO:absl:__________________________________________________________________________________________________\n",
      "INFO:absl:concatenate (Concatenate)       (None, 4)            0           Sepal.Length_xf[0][0]            \n",
      "INFO:absl:                                                                 Sepal.Width_xf[0][0]             \n",
      "INFO:absl:                                                                 Petal.Length_xf[0][0]            \n",
      "INFO:absl:                                                                 Petal.Width_xf[0][0]             \n",
      "INFO:absl:__________________________________________________________________________________________________\n",
      "INFO:absl:dense (Dense)                   (None, 10)           50          concatenate[0][0]                \n",
      "INFO:absl:__________________________________________________________________________________________________\n",
      "INFO:absl:dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
      "INFO:absl:__________________________________________________________________________________________________\n",
      "INFO:absl:dense_2 (Dense)                 (None, 3)            33          dense_1[0][0]                    \n",
      "INFO:absl:==================================================================================================\n",
      "INFO:absl:Total params: 193\n",
      "INFO:absl:Trainable params: 193\n",
      "INFO:absl:Non-trainable params: 0\n",
      "INFO:absl:__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "   1/2000 [..............................] - ETA: 34:34 - loss: 1.3640 - sparse_categorical_accuracy: 0.3000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-10 14:37:45.181898: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
      "2021-11-10 14:37:45.181945: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  35/2000 [..............................] - ETA: 28s - loss: 0.8800 - sparse_categorical_accuracy: 0.6257"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-10 14:37:45.500577: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2021-11-10 14:37:45.501513: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1748] CUPTI activity buffer flushed\n",
      "2021-11-10 14:37:45.522988: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:673]  GpuTracer has collected 86 callback api events and 83 activity events. \n",
      "2021-11-10 14:37:45.525715: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n",
      "2021-11-10 14:37:45.529116: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: pipelines/iris/Trainer/model_run/11/train/plugins/profile/2021_11_10_14_37_45\n",
      "\n",
      "2021-11-10 14:37:45.531130: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to pipelines/iris/Trainer/model_run/11/train/plugins/profile/2021_11_10_14_37_45/EkE-Legion5.trace.json.gz\n",
      "2021-11-10 14:37:45.537202: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: pipelines/iris/Trainer/model_run/11/train/plugins/profile/2021_11_10_14_37_45\n",
      "\n",
      "2021-11-10 14:37:45.537642: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to pipelines/iris/Trainer/model_run/11/train/plugins/profile/2021_11_10_14_37_45/EkE-Legion5.memory_profile.json.gz\n",
      "2021-11-10 14:37:45.537907: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: pipelines/iris/Trainer/model_run/11/train/plugins/profile/2021_11_10_14_37_45\n",
      "Dumped tool data for xplane.pb to pipelines/iris/Trainer/model_run/11/train/plugins/profile/2021_11_10_14_37_45/EkE-Legion5.xplane.pb\n",
      "Dumped tool data for overview_page.pb to pipelines/iris/Trainer/model_run/11/train/plugins/profile/2021_11_10_14_37_45/EkE-Legion5.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to pipelines/iris/Trainer/model_run/11/train/plugins/profile/2021_11_10_14_37_45/EkE-Legion5.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to pipelines/iris/Trainer/model_run/11/train/plugins/profile/2021_11_10_14_37_45/EkE-Legion5.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to pipelines/iris/Trainer/model_run/11/train/plugins/profile/2021_11_10_14_37_45/EkE-Legion5.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1347/2000 [===================>..........] - ETA: 3s - loss: 0.0529 - sparse_categorical_accuracy: 0.9782"
     ]
    }
   ],
   "source": [
    "pipeline = _create_pipeline(\n",
    "      pipeline_name=PIPELINE_NAME,\n",
    "      pipeline_root=PIPELINE_ROOT,\n",
    "      data_root=DATA_ROOT,\n",
    "      module_file=_module_file,\n",
    "      serving_model_dir=SERVING_MODEL_DIR,\n",
    "      metadata_path=METADATA_PATH\n",
    ")\n",
    "\n",
    "tfx.orchestration.LocalDagRunner().run(pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tfx.types import standard_component_specs\n",
    "from tfx.orchestration.portable.mlmd import execution_lib\n",
    "from tfx.orchestration.metadata import Metadata\n",
    "from tfx.orchestration.experimental.interactive import visualizations\n",
    "from ml_metadata.proto import metadata_store_pb2\n",
    "\n",
    "def get_latest_artifact(component_id):\n",
    "    metadata_connection_config = tfx.orchestration.metadata.sqlite_metadata_connection_config(METADATA_PATH)\n",
    "\n",
    "    with Metadata(metadata_connection_config) as metadata_handler:\n",
    "        context = metadata_handler.store.get_context_by_type_and_name('node', f'{PIPELINE_NAME}.{component_id}')\n",
    "        executions = metadata_handler.store.get_executions_by_context(context.id)\n",
    "        latest_execution = max(executions, key=lambda e: e.last_update_time_since_epoch)\n",
    "\n",
    "        return execution_lib.get_artifacts_dict(metadata_handler, latest_execution.id, metadata_store_pb2.Event.OUTPUT)\n",
    "    \n",
    "def visualize(artifact):\n",
    "    visualization = visualizations.get_registry().get_visualization(artifact.type_name)\n",
    "    visualization.display(artifact)\n",
    "    \n",
    "    \n",
    "from tfx.orchestration.experimental.interactive import standard_visualizations\n",
    "standard_visualizations.register_standard_visualizations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StatisticsGen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistic_artifact = get_latest_artifact(\"StatisticsGen\")['statistics'][0]\n",
    "\n",
    "visualize(statistic_artifact)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SchemaGen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "schema_artifact = get_latest_artifact(\"SchemaGen\")['schema'][0]\n",
    "\n",
    "visualize(schema_artifact)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ExampleValidator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_validator_articaft = get_latest_artifact(\"ExampleValidator\")['anomalies'][0]\n",
    "\n",
    "visualize(example_validator_articaft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_run_artifact_dir = get_latest_artifact(\"Trainer\")['model_run'][0].uri\n",
    "\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir {model_run_artifact_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
