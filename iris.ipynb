{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from tfx import v1 as tfx\n",
    "\n",
    "    if tfx.__version__ != \"1.4.0\":\n",
    "        raise ModuleNotFoundError\n",
    "except ModuleNotFoundError:\n",
    "    !pip install tfx==1.4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tfx.orchestration.experimental.interactive.notebook_extensions.skip extension is already loaded. To reload it, use:\n",
      "  %reload_ext tfx.orchestration.experimental.interactive.notebook_extensions.skip\n",
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n",
      "TFX version: 1.4.0\n",
      "TensorFlow version: 2.6.2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_model_analysis as tfma\n",
    "\n",
    "%load_ext tfx.orchestration.experimental.interactive.notebook_extensions.skip\n",
    "%load_ext tensorboard\n",
    "\n",
    "print('TFX version: {}'.format(tfx.__version__))\n",
    "print('TensorFlow version: {}'.format(tf.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from absl import logging\n",
    "import uuid\n",
    "\n",
    "logging.set_verbosity(logging.INFO)\n",
    "\n",
    "PIPELINE_NAME = \"iris\"\n",
    "PIPELINE_ROOT = os.path.join('pipelines', PIPELINE_NAME)\n",
    "METADATA_PATH = os.path.join('metadata', PIPELINE_NAME, 'metadata.db')\n",
    "SERVING_MODEL_DIR = os.path.join('serving_model', PIPELINE_NAME)\n",
    "\n",
    "DATA_ROOT = os.path.join(\"data\")\n",
    "os.makedirs(DATA_ROOT, exist_ok=True)\n",
    "\n",
    "if False:\n",
    "    TENSORBOARD_DIR = os.path.join('/tmp', 'tensorboard', str(uuid.uuid4()))\n",
    "    os.makedirs(TENSORBOARD_DIR, exist_ok=True)\n",
    "else:\n",
    "    TENSORBOARD_DIR = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Iris classes & features](assets/iris_classes.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepallength,sepalwidth,petallength,petalwidth,class\r",
      "\r\n",
      "5.1,3.5,1.4,0.2,Iris-setosa\r",
      "\r\n",
      "4.9,3.0,1.4,0.2,Iris-setosa\r",
      "\r\n",
      "4.7,3.2,1.3,0.2,Iris-setosa\r",
      "\r\n",
      "4.6,3.1,1.5,0.2,Iris-setosa\r",
      "\r\n",
      "5.0,3.6,1.4,0.2,Iris-setosa\r",
      "\r\n",
      "5.4,3.9,1.7,0.4,Iris-setosa\r",
      "\r\n",
      "4.6,3.4,1.4,0.3,Iris-setosa\r",
      "\r\n",
      "5.0,3.4,1.5,0.2,Iris-setosa\r",
      "\r\n",
      "4.4,2.9,1.4,0.2,Iris-setosa\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "\n",
    "_data_url = 'https://datahub.io/machine-learning/iris/r/iris.csv'\n",
    "_data_filepath = os.path.join(DATA_ROOT, \"data.csv\")\n",
    "\n",
    "urllib.request.urlretrieve(_data_url, _data_filepath)\n",
    "\n",
    "!head {_data_filepath}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data entries: 150\n"
     ]
    }
   ],
   "source": [
    "with open(_data_filepath, \"r\") as file_object:\n",
    "    print(\"Number of data entries:\", len(file_object.readlines())-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create TFX pipeline and run it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![TFX pipline](assets/tfx_pipeline.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def _create_pipeline(pipeline_name: str, pipeline_root: str, data_root: str,\n",
    "                     module_file: str, serving_model_dir: str,\n",
    "                     metadata_path: str) -> tfx.dsl.Pipeline:\n",
    "    # Brings data into the pipeline or otherwise joins/converts training data.\n",
    "    example_gen = tfx.components.CsvExampleGen(\n",
    "        input_base=data_root,\n",
    "        output_config=tfx.proto.Output(\n",
    "            split_config=tfx.proto.SplitConfig(splits=[\n",
    "                tfx.proto.SplitConfig.Split(name='train', hash_buckets=2),\n",
    "                tfx.proto.SplitConfig.Split(name='eval', hash_buckets=1)\n",
    "            ])\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Computes statistics over data for visualization and example validation.\n",
    "    statistics_gen = tfx.components.StatisticsGen(\n",
    "        examples=example_gen.outputs['examples']\n",
    "    )\n",
    "\n",
    "    # Generate a schema based on your data statistics.\n",
    "    # A schema defines the expected bounds, types, and properties of the features in your dataset.\n",
    "    schema_gen = tfx.components.SchemaGen(\n",
    "        statistics=statistics_gen.outputs['statistics'],\n",
    "        infer_feature_shape=True\n",
    "    )\n",
    "\n",
    "    # Performs anomaly detection based on statistics and data schema.\n",
    "    example_validator = tfx.components.ExampleValidator(\n",
    "        statistics=statistics_gen.outputs['statistics'],\n",
    "        schema=schema_gen.outputs['schema']\n",
    "    )\n",
    "\n",
    "    # Transforms input data using 'preprocessing_fn' in the 'module_file'.\n",
    "    transform = tfx.components.Transform(\n",
    "        examples=example_gen.outputs['examples'],\n",
    "        schema=schema_gen.outputs['schema'],\n",
    "        materialize=False,\n",
    "        module_file=module_file\n",
    "    )\n",
    "\n",
    "    # Tunes the hyperparameters using the 'tuner_fn' method in the 'module_file'.\n",
    "    tuner = tfx.components.Tuner(\n",
    "        module_file=module_file,\n",
    "        examples=example_gen.outputs['examples'],\n",
    "        schema=schema_gen.outputs['schema'],\n",
    "        transform_graph=transform.outputs['transform_graph'],\n",
    "        train_args=tfx.proto.TrainArgs(num_steps=20),\n",
    "        eval_args=tfx.proto.EvalArgs(num_steps=5)\n",
    "    )\n",
    "\n",
    "    # Trains a model using the 'run_fn' method in the 'module_file'.\n",
    "    trainer = tfx.components.Trainer(\n",
    "        module_file=module_file,\n",
    "        examples=example_gen.outputs['examples'],\n",
    "        schema=schema_gen.outputs['schema'],\n",
    "        transform_graph=transform.outputs['transform_graph'],\n",
    "        hyperparameters=tuner.outputs['best_hyperparameters'],\n",
    "        train_args=tfx.proto.TrainArgs(num_steps=2000),\n",
    "        eval_args=tfx.proto.EvalArgs(num_steps=5),\n",
    "        custom_config={'tensorboard_dir': TENSORBOARD_DIR}\n",
    "    )\n",
    "\n",
    "    # Get the latest blessed model for model validation.\n",
    "    model_resolver = tfx.dsl.Resolver(\n",
    "        strategy_class=tfx.dsl.experimental.LatestBlessedModelStrategy,\n",
    "        model=tfx.dsl.Channel(type=tfx.types.standard_artifacts.Model),\n",
    "        model_blessing=tfx.dsl.Channel(type=tfx.types.standard_artifacts.ModelBlessing)\n",
    "    ).with_id('latest_blessed_model_resolver')\n",
    "\n",
    "    # Uses TFMA to compute evaluation statistics over features of a model and\n",
    "    # perform quality validation of a candidate model (compared to a baseline).\n",
    "    eval_config = tfma.EvalConfig(\n",
    "        model_specs=[\n",
    "            tfma.ModelSpec(\n",
    "                signature_name='serving_default',\n",
    "                label_key='class',\n",
    "                preprocessing_function_names=['transform_features'])\n",
    "        ],\n",
    "        slicing_specs=[tfma.SlicingSpec()],\n",
    "        metrics_specs=[tfma.MetricsSpec(\n",
    "            metrics=[tfma.MetricConfig(\n",
    "                class_name='SparseCategoricalAccuracy',\n",
    "                threshold=tfma.MetricThreshold(\n",
    "                    value_threshold=tfma.GenericValueThreshold(lower_bound={'value': 0.6}),\n",
    "                    change_threshold=tfma.GenericChangeThreshold(direction=tfma.MetricDirection.HIGHER_IS_BETTER, absolute={'value': -1e-10})\n",
    "                )\n",
    "            )]\n",
    "        )]\n",
    "    )\n",
    "    evaluator = tfx.components.Evaluator(\n",
    "        examples=example_gen.outputs['examples'],\n",
    "        model=trainer.outputs['model'],\n",
    "        baseline_model=model_resolver.outputs['model'],\n",
    "        eval_config=eval_config\n",
    "    )\n",
    "\n",
    "    # Pushes the model to a filesystem destination.\n",
    "    pusher = tfx.components.Pusher(\n",
    "        model=trainer.outputs['model'],\n",
    "        model_blessing=evaluator.outputs['blessing'],\n",
    "        push_destination=tfx.proto.PushDestination(filesystem=tfx.proto.PushDestination\n",
    "                                                   .Filesystem(base_directory=serving_model_dir))\n",
    "    )\n",
    "\n",
    "    components = [\n",
    "        example_gen,\n",
    "        statistics_gen,\n",
    "        schema_gen,\n",
    "        example_validator,\n",
    "        transform,\n",
    "        tuner,\n",
    "        trainer,\n",
    "        model_resolver,\n",
    "        evaluator,\n",
    "        pusher,\n",
    "    ]\n",
    "\n",
    "    return tfx.dsl.Pipeline(\n",
    "        pipeline_name=pipeline_name,\n",
    "        pipeline_root=pipeline_root,\n",
    "        metadata_connection_config=tfx.orchestration.metadata.sqlite_metadata_connection_config(metadata_path),\n",
    "        components=components\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Excluding no splits because exclude_splits is not set.\n",
      "INFO:absl:Excluding no splits because exclude_splits is not set.\n",
      "INFO:absl:Excluding no splits because exclude_splits is not set.\n"
     ]
    }
   ],
   "source": [
    "_module_file = 'iris_utils.py'\n",
    "\n",
    "pipeline = _create_pipeline(\n",
    "    pipeline_name=PIPELINE_NAME,\n",
    "    pipeline_root=PIPELINE_ROOT,\n",
    "    data_root=DATA_ROOT,\n",
    "    module_file=_module_file,\n",
    "    serving_model_dir=SERVING_MODEL_DIR,\n",
    "    metadata_path=METADATA_PATH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TENSORBOARD_DIR:\n",
    "    %tensorboard --logdir {TENSORBOARD_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 6 Complete [00h 00m 00s]\n",
      "val_accuracy: 0.8799999952316284\n",
      "\n",
      "Best val_accuracy So Far: 0.9300000071525574\n",
      "Total elapsed time: 00h 00m 06s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n",
      "INFO:absl:Finished tuning... Tuner ID: tuner0\n",
      "INFO:absl:Best HyperParameters: {'space': [{'class_name': 'Int', 'config': {'name': 'dnn_hidden_layer_0', 'default': None, 'conditions': [], 'min_value': 100, 'max_value': 150, 'step': 1, 'sampling': None}}, {'class_name': 'Int', 'config': {'name': 'dnn_hidden_layer_1', 'default': None, 'conditions': [], 'min_value': 50, 'max_value': 70, 'step': 1, 'sampling': None}}], 'values': {'dnn_hidden_layer_0': 148, 'dnn_hidden_layer_1': 61}}\n",
      "INFO:absl:Best Hyperparameters are written to pipelines/iris/Tuner/best_hyperparameters/469/best_hyperparameters.txt.\n",
      "INFO:absl:Cleaning up stateless execution info.\n",
      "INFO:absl:Execution 469 succeeded.\n",
      "INFO:absl:Cleaning up stateful execution info.\n",
      "INFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'best_hyperparameters': [Artifact(artifact: uri: \"pipelines/iris/Tuner/best_hyperparameters/469\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"iris:2021-11-30T11:37:57.542539:Tuner:best_hyperparameters:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.4.0\"\n",
      "  }\n",
      "}\n",
      ", artifact_type: name: \"HyperParameters\"\n",
      ")]}) for execution 469\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Component Tuner is finished.\n",
      "INFO:absl:Component Trainer is running.\n",
      "INFO:absl:Running launcher for node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.trainer.component.Trainer\"\n",
      "  }\n",
      "  id: \"Trainer\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"iris\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2021-11-30T11:37:57.542539\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"iris.Trainer\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"CsvExampleGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"iris\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2021-11-30T11:37:57.542539\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"iris.CsvExampleGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Examples\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"examples\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"hyperparameters\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"Tuner\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"iris\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2021-11-30T11:37:57.542539\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"iris.Tuner\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"HyperParameters\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"best_hyperparameters\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"schema\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"SchemaGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"iris\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2021-11-30T11:37:57.542539\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"iris.SchemaGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Schema\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"schema\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"transform_graph\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"Transform\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"iris\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2021-11-30T11:37:57.542539\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"iris.Transform\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"TransformGraph\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"transform_graph\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"model\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Model\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"model_run\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ModelRun\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"custom_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\\"tensorboard_dir\\\": null}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"eval_args\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"num_steps\\\": 5\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"module_path\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"iris_utils@pipelines/iris/_wheels/tfx_user_code_Trainer-0.0+775fd8198cb1c10f66336ab2e4c1c4661db15ddbd2d8d3631f3d3c8a0e2c88e2-py3-none-any.whl\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"train_args\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"num_steps\\\": 2000\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"CsvExampleGen\"\n",
      "upstream_nodes: \"SchemaGen\"\n",
      "upstream_nodes: \"Transform\"\n",
      "upstream_nodes: \"Tuner\"\n",
      "downstream_nodes: \"Evaluator\"\n",
      "downstream_nodes: \"Pusher\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      "\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Going to run a new execution 470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in pipelines/iris/Tuner/tensorboards/469/iris_tune_model\n",
      "Showing 10 best trials\n",
      "Objective(name='val_accuracy', direction='max')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "dnn_hidden_layer_0: 148\n",
      "dnn_hidden_layer_1: 61\n",
      "Score: 0.9300000071525574\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "dnn_hidden_layer_0: 110\n",
      "dnn_hidden_layer_1: 65\n",
      "Score: 0.9100000262260437\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "dnn_hidden_layer_0: 104\n",
      "dnn_hidden_layer_1: 64\n",
      "Score: 0.9100000262260437\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "dnn_hidden_layer_0: 147\n",
      "dnn_hidden_layer_1: 51\n",
      "Score: 0.8799999952316284\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "dnn_hidden_layer_0: 149\n",
      "dnn_hidden_layer_1: 60\n",
      "Score: 0.8799999952316284\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "dnn_hidden_layer_0: 150\n",
      "dnn_hidden_layer_1: 69\n",
      "Score: 0.8600000143051147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Going to run a new execution: ExecutionInfo(execution_id=470, input_dict={'examples': [Artifact(artifact: id: 799\n",
      "type_id: 15\n",
      "uri: \"pipelines/iris/CsvExampleGen/examples/463\"\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value {\n",
      "    string_value: \"[\\\"train\\\", \\\"eval\\\"]\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"file_format\"\n",
      "  value {\n",
      "    string_value: \"tfrecords_gzip\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"input_fingerprint\"\n",
      "  value {\n",
      "    string_value: \"split:single_split,num_files:1,total_bytes:4753,xor_checksum:1638268676,sum_checksum:1638268676\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"iris:2021-11-30T11:37:57.542539:CsvExampleGen:examples:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"payload_format\"\n",
      "  value {\n",
      "    string_value: \"FORMAT_TF_EXAMPLE\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"span\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.4.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "create_time_since_epoch: 1638268678755\n",
      "last_update_time_since_epoch: 1638268678755\n",
      ", artifact_type: id: 15\n",
      "name: \"Examples\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value: INT\n",
      "}\n",
      ")], 'hyperparameters': [Artifact(artifact: id: 810\n",
      "type_id: 26\n",
      "uri: \"pipelines/iris/Tuner/best_hyperparameters/469\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"iris:2021-11-30T11:37:57.542539:Tuner:best_hyperparameters:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.4.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "create_time_since_epoch: 1638268703941\n",
      "last_update_time_since_epoch: 1638268703941\n",
      ", artifact_type: id: 26\n",
      "name: \"HyperParameters\"\n",
      ")], 'transform_graph': [Artifact(artifact: id: 809\n",
      "type_id: 23\n",
      "uri: \"pipelines/iris/Transform/transform_graph/468\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"iris:2021-11-30T11:37:57.542539:Transform:transform_graph:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.4.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "create_time_since_epoch: 1638268694643\n",
      "last_update_time_since_epoch: 1638268694643\n",
      ", artifact_type: id: 23\n",
      "name: \"TransformGraph\"\n",
      ")], 'schema': [Artifact(artifact: id: 801\n",
      "type_id: 19\n",
      "uri: \"pipelines/iris/SchemaGen/schema/466\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"iris:2021-11-30T11:37:57.542539:SchemaGen:schema:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.4.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "create_time_since_epoch: 1638268681368\n",
      "last_update_time_since_epoch: 1638268681368\n",
      ", artifact_type: id: 19\n",
      "name: \"Schema\"\n",
      ")]}, output_dict=defaultdict(<class 'list'>, {'model_run': [Artifact(artifact: uri: \"pipelines/iris/Trainer/model_run/470\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"iris:2021-11-30T11:37:57.542539:Trainer:model_run:0\"\n",
      "  }\n",
      "}\n",
      ", artifact_type: name: \"ModelRun\"\n",
      ")], 'model': [Artifact(artifact: uri: \"pipelines/iris/Trainer/model/470\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"iris:2021-11-30T11:37:57.542539:Trainer:model:0\"\n",
      "  }\n",
      "}\n",
      ", artifact_type: name: \"Model\"\n",
      ")]}), exec_properties={'train_args': '{\\n  \"num_steps\": 2000\\n}', 'eval_args': '{\\n  \"num_steps\": 5\\n}', 'module_path': 'iris_utils@pipelines/iris/_wheels/tfx_user_code_Trainer-0.0+775fd8198cb1c10f66336ab2e4c1c4661db15ddbd2d8d3631f3d3c8a0e2c88e2-py3-none-any.whl', 'custom_config': '{\"tensorboard_dir\": null}'}, execution_output_uri='pipelines/iris/Trainer/.system/executor_execution/470/executor_output.pb', stateful_working_dir='pipelines/iris/Trainer/.system/stateful_working_dir/2021-11-30T11:37:57.542539', tmp_dir='pipelines/iris/Trainer/.system/executor_execution/470/.temp/', pipeline_node=node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.trainer.component.Trainer\"\n",
      "  }\n",
      "  id: \"Trainer\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"iris\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2021-11-30T11:37:57.542539\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"iris.Trainer\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"CsvExampleGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"iris\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2021-11-30T11:37:57.542539\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"iris.CsvExampleGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Examples\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"examples\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"hyperparameters\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"Tuner\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"iris\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2021-11-30T11:37:57.542539\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"iris.Tuner\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"HyperParameters\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"best_hyperparameters\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"schema\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"SchemaGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"iris\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2021-11-30T11:37:57.542539\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"iris.SchemaGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Schema\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"schema\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"transform_graph\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"Transform\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"iris\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2021-11-30T11:37:57.542539\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"iris.Transform\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"TransformGraph\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"transform_graph\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"model\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Model\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"model_run\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ModelRun\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"custom_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\\"tensorboard_dir\\\": null}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"eval_args\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"num_steps\\\": 5\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"module_path\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"iris_utils@pipelines/iris/_wheels/tfx_user_code_Trainer-0.0+775fd8198cb1c10f66336ab2e4c1c4661db15ddbd2d8d3631f3d3c8a0e2c88e2-py3-none-any.whl\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"train_args\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"num_steps\\\": 2000\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"CsvExampleGen\"\n",
      "upstream_nodes: \"SchemaGen\"\n",
      "upstream_nodes: \"Transform\"\n",
      "upstream_nodes: \"Tuner\"\n",
      "downstream_nodes: \"Evaluator\"\n",
      "downstream_nodes: \"Pusher\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      ", pipeline_info=id: \"iris\"\n",
      ", pipeline_run_id='2021-11-30T11:37:57.542539')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Train on the 'train' split when train_args.splits is not set.\n",
      "INFO:absl:Evaluate on the 'eval' split when eval_args.splits is not set.\n",
      "INFO:absl:udf_utils.get_fn {'train_args': '{\\n  \"num_steps\": 2000\\n}', 'eval_args': '{\\n  \"num_steps\": 5\\n}', 'module_path': 'iris_utils@pipelines/iris/_wheels/tfx_user_code_Trainer-0.0+775fd8198cb1c10f66336ab2e4c1c4661db15ddbd2d8d3631f3d3c8a0e2c88e2-py3-none-any.whl', 'custom_config': '{\"tensorboard_dir\": null}'} 'run_fn'\n",
      "INFO:absl:Installing 'pipelines/iris/_wheels/tfx_user_code_Trainer-0.0+775fd8198cb1c10f66336ab2e4c1c4661db15ddbd2d8d3631f3d3c8a0e2c88e2-py3-none-any.whl' to a temporary directory.\n",
      "INFO:absl:Executing: ['/home/ekrem/.pyenv/versions/3.8.7/envs/tfx/bin/python3.8', '-m', 'pip', 'install', '--target', '/tmp/tmp6k0ji94c', 'pipelines/iris/_wheels/tfx_user_code_Trainer-0.0+775fd8198cb1c10f66336ab2e4c1c4661db15ddbd2d8d3631f3d3c8a0e2c88e2-py3-none-any.whl']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./pipelines/iris/_wheels/tfx_user_code_Trainer-0.0+775fd8198cb1c10f66336ab2e4c1c4661db15ddbd2d8d3631f3d3c8a0e2c88e2-py3-none-any.whl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Successfully installed 'pipelines/iris/_wheels/tfx_user_code_Trainer-0.0+775fd8198cb1c10f66336ab2e4c1c4661db15ddbd2d8d3631f3d3c8a0e2c88e2-py3-none-any.whl'.\n",
      "INFO:absl:Training model.\n",
      "INFO:absl:Feature class has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature petallength has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature petalwidth has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature sepallength has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature sepalwidth has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: tfx-user-code-Trainer\n",
      "Successfully installed tfx-user-code-Trainer-0.0+775fd8198cb1c10f66336ab2e4c1c4661db15ddbd2d8d3631f3d3c8a0e2c88e2\n",
      "INFO:tensorflow:tensorflow_text is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_text is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:struct2tensor is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:struct2tensor is not available.\n",
      "INFO:absl:Feature class has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature petallength has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature petalwidth has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature sepallength has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature sepalwidth has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "2021-11-30 11:38:25.708219: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
      "2021-11-30 11:38:25.708285: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n",
      "2021-11-30 11:38:25.817419: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n",
      "2021-11-30 11:38:25.819193: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1748] CUPTI activity buffer flushed\n",
      "INFO:absl:Model: \"model_1\"\n",
      "INFO:absl:__________________________________________________________________________________________________\n",
      "INFO:absl:Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "INFO:absl:==================================================================================================\n",
      "INFO:absl:sepallength (InputLayer)        [(None, 1)]          0                                            \n",
      "INFO:absl:__________________________________________________________________________________________________\n",
      "INFO:absl:sepalwidth (InputLayer)         [(None, 1)]          0                                            \n",
      "INFO:absl:__________________________________________________________________________________________________\n",
      "INFO:absl:petallength (InputLayer)        [(None, 1)]          0                                            \n",
      "INFO:absl:__________________________________________________________________________________________________\n",
      "INFO:absl:petalwidth (InputLayer)         [(None, 1)]          0                                            \n",
      "INFO:absl:__________________________________________________________________________________________________\n",
      "INFO:absl:concatenate_1 (Concatenate)     (None, 4)            0           sepallength[0][0]                \n",
      "INFO:absl:                                                                 sepalwidth[0][0]                 \n",
      "INFO:absl:                                                                 petallength[0][0]                \n",
      "INFO:absl:                                                                 petalwidth[0][0]                 \n",
      "INFO:absl:__________________________________________________________________________________________________\n",
      "INFO:absl:dense_3 (Dense)                 (None, 148)          740         concatenate_1[0][0]              \n",
      "INFO:absl:__________________________________________________________________________________________________\n",
      "INFO:absl:dense_4 (Dense)                 (None, 61)           9089        dense_3[0][0]                    \n",
      "INFO:absl:__________________________________________________________________________________________________\n",
      "INFO:absl:dense_5 (Dense)                 (None, 3)            186         dense_4[0][0]                    \n",
      "INFO:absl:==================================================================================================\n",
      "INFO:absl:Total params: 10,015\n",
      "INFO:absl:Trainable params: 10,015\n",
      "INFO:absl:Non-trainable params: 0\n",
      "INFO:absl:__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   2/2000 [..............................] - ETA: 5:23 - loss: 0.9363 - accuracy: 0.5750 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-30 11:38:26.316082: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
      "2021-11-30 11:38:26.316137: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n",
      "2021-11-30 11:38:26.487342: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2021-11-30 11:38:26.488336: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1748] CUPTI activity buffer flushed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  50/2000 [..............................] - ETA: 16s - loss: 0.1688 - accuracy: 0.9260"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-30 11:38:26.528531: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:673]  GpuTracer has collected 89 callback api events and 86 activity events. \n",
      "2021-11-30 11:38:26.531035: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n",
      "2021-11-30 11:38:26.534336: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: pipelines/iris/Trainer/model_run/470/train/plugins/profile/2021_11_30_11_38_26\n",
      "\n",
      "2021-11-30 11:38:26.536425: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to pipelines/iris/Trainer/model_run/470/train/plugins/profile/2021_11_30_11_38_26/EkE-Legion5.trace.json.gz\n",
      "2021-11-30 11:38:26.541113: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: pipelines/iris/Trainer/model_run/470/train/plugins/profile/2021_11_30_11_38_26\n",
      "\n",
      "2021-11-30 11:38:26.541819: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to pipelines/iris/Trainer/model_run/470/train/plugins/profile/2021_11_30_11_38_26/EkE-Legion5.memory_profile.json.gz\n",
      "2021-11-30 11:38:26.542684: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: pipelines/iris/Trainer/model_run/470/train/plugins/profile/2021_11_30_11_38_26\n",
      "Dumped tool data for xplane.pb to pipelines/iris/Trainer/model_run/470/train/plugins/profile/2021_11_30_11_38_26/EkE-Legion5.xplane.pb\n",
      "Dumped tool data for overview_page.pb to pipelines/iris/Trainer/model_run/470/train/plugins/profile/2021_11_30_11_38_26/EkE-Legion5.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to pipelines/iris/Trainer/model_run/470/train/plugins/profile/2021_11_30_11_38_26/EkE-Legion5.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to pipelines/iris/Trainer/model_run/470/train/plugins/profile/2021_11_30_11_38_26/EkE-Legion5.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to pipelines/iris/Trainer/model_run/470/train/plugins/profile/2021_11_30_11_38_26/EkE-Legion5.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 9s 4ms/step - loss: 0.0071 - accuracy: 0.9970 - val_loss: 2.0049 - val_accuracy: 0.9000\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.Socket(zmq.PUSH) at 0x7fbd2f8b8820>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:serve_transformed_features = {'petallength': <tf.Tensor 'transform_features_layer/StatefulPartitionedCall:1' shape=(None, 1) dtype=float32>, 'petalwidth': <tf.Tensor 'transform_features_layer/StatefulPartitionedCall:2' shape=(None, 1) dtype=float32>, 'sepallength': <tf.Tensor 'transform_features_layer/StatefulPartitionedCall:3' shape=(None, 1) dtype=float32>, 'sepalwidth': <tf.Tensor 'transform_features_layer/StatefulPartitionedCall:4' shape=(None, 1) dtype=float32>}\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.Socket(zmq.PUSH) at 0x7fbd2f8b8820>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.Socket(zmq.PUSH) at 0x7fbd2f8b8820>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:eval_transformed_features = {'class': <tf.Tensor 'transform_features_layer/StatefulPartitionedCall:0' shape=(None, 1) dtype=int64>, 'petallength': <tf.Tensor 'transform_features_layer/StatefulPartitionedCall:1' shape=(None, 1) dtype=float32>, 'petalwidth': <tf.Tensor 'transform_features_layer/StatefulPartitionedCall:2' shape=(None, 1) dtype=float32>, 'sepallength': <tf.Tensor 'transform_features_layer/StatefulPartitionedCall:3' shape=(None, 1) dtype=float32>, 'sepalwidth': <tf.Tensor 'transform_features_layer/StatefulPartitionedCall:4' shape=(None, 1) dtype=float32>}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: pipelines/iris/Trainer/model/470/Format-Serving/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: pipelines/iris/Trainer/model/470/Format-Serving/assets\n",
      "INFO:absl:Training complete. Model written to pipelines/iris/Trainer/model/470/Format-Serving. ModelRun written to pipelines/iris/Trainer/model_run/470\n",
      "INFO:absl:Cleaning up stateless execution info.\n",
      "INFO:absl:Execution 470 succeeded.\n",
      "INFO:absl:Cleaning up stateful execution info.\n",
      "INFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'model_run': [Artifact(artifact: uri: \"pipelines/iris/Trainer/model_run/470\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"iris:2021-11-30T11:37:57.542539:Trainer:model_run:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.4.0\"\n",
      "  }\n",
      "}\n",
      ", artifact_type: name: \"ModelRun\"\n",
      ")], 'model': [Artifact(artifact: uri: \"pipelines/iris/Trainer/model/470\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"iris:2021-11-30T11:37:57.542539:Trainer:model:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.4.0\"\n",
      "  }\n",
      "}\n",
      ", artifact_type: name: \"Model\"\n",
      ")]}) for execution 470\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Component Trainer is finished.\n",
      "INFO:absl:Component Evaluator is running.\n",
      "INFO:absl:Running launcher for node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.evaluator.component.Evaluator\"\n",
      "  }\n",
      "  id: \"Evaluator\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"iris\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2021-11-30T11:37:57.542539\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"iris.Evaluator\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"baseline_model\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"latest_blessed_model_resolver\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"iris\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2021-11-30T11:37:57.542539\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"iris.latest_blessed_model_resolver\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Model\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"model\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"CsvExampleGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"iris\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2021-11-30T11:37:57.542539\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"iris.CsvExampleGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Examples\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"examples\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"model\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"Trainer\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"iris\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2021-11-30T11:37:57.542539\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"iris.Trainer\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Model\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"model\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"blessing\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ModelBlessing\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"evaluation\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ModelEvaluation\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"eval_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"metrics_specs\\\": [\\n    {\\n      \\\"metrics\\\": [\\n        {\\n          \\\"class_name\\\": \\\"SparseCategoricalAccuracy\\\",\\n          \\\"threshold\\\": {\\n            \\\"change_threshold\\\": {\\n              \\\"absolute\\\": -1e-10,\\n              \\\"direction\\\": \\\"HIGHER_IS_BETTER\\\"\\n            },\\n            \\\"value_threshold\\\": {\\n              \\\"lower_bound\\\": 0.6\\n            }\\n          }\\n        }\\n      ]\\n    }\\n  ],\\n  \\\"model_specs\\\": [\\n    {\\n      \\\"label_key\\\": \\\"class\\\",\\n      \\\"preprocessing_function_names\\\": [\\n        \\\"transform_features\\\"\\n      ],\\n      \\\"signature_name\\\": \\\"serving_default\\\"\\n    }\\n  ],\\n  \\\"slicing_specs\\\": [\\n    {}\\n  ]\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"example_splits\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"null\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"fairness_indicator_thresholds\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"null\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"CsvExampleGen\"\n",
      "upstream_nodes: \"Trainer\"\n",
      "upstream_nodes: \"latest_blessed_model_resolver\"\n",
      "downstream_nodes: \"Pusher\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      "\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Going to run a new execution 471\n",
      "INFO:absl:Going to run a new execution: ExecutionInfo(execution_id=471, input_dict={'baseline_model': [Artifact(artifact: id: 726\n",
      "type_id: 28\n",
      "uri: \"pipelines/iris/Trainer/model/420\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"iris:2021-11-29T18:53:51.107789:Trainer:model:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.4.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "create_time_since_epoch: 1638208474106\n",
      "last_update_time_since_epoch: 1638208474106\n",
      ", artifact_type: id: 28\n",
      "name: \"Model\"\n",
      ")], 'model': [Artifact(artifact: id: 812\n",
      "type_id: 28\n",
      "uri: \"pipelines/iris/Trainer/model/470\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"iris:2021-11-30T11:37:57.542539:Trainer:model:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.4.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "create_time_since_epoch: 1638268719029\n",
      "last_update_time_since_epoch: 1638268719029\n",
      ", artifact_type: id: 28\n",
      "name: \"Model\"\n",
      ")], 'examples': [Artifact(artifact: id: 799\n",
      "type_id: 15\n",
      "uri: \"pipelines/iris/CsvExampleGen/examples/463\"\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value {\n",
      "    string_value: \"[\\\"train\\\", \\\"eval\\\"]\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"file_format\"\n",
      "  value {\n",
      "    string_value: \"tfrecords_gzip\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"input_fingerprint\"\n",
      "  value {\n",
      "    string_value: \"split:single_split,num_files:1,total_bytes:4753,xor_checksum:1638268676,sum_checksum:1638268676\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"iris:2021-11-30T11:37:57.542539:CsvExampleGen:examples:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"payload_format\"\n",
      "  value {\n",
      "    string_value: \"FORMAT_TF_EXAMPLE\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"span\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.4.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "create_time_since_epoch: 1638268678755\n",
      "last_update_time_since_epoch: 1638268678755\n",
      ", artifact_type: id: 15\n",
      "name: \"Examples\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value: INT\n",
      "}\n",
      ")]}, output_dict=defaultdict(<class 'list'>, {'blessing': [Artifact(artifact: uri: \"pipelines/iris/Evaluator/blessing/471\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"iris:2021-11-30T11:37:57.542539:Evaluator:blessing:0\"\n",
      "  }\n",
      "}\n",
      ", artifact_type: name: \"ModelBlessing\"\n",
      ")], 'evaluation': [Artifact(artifact: uri: \"pipelines/iris/Evaluator/evaluation/471\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"iris:2021-11-30T11:37:57.542539:Evaluator:evaluation:0\"\n",
      "  }\n",
      "}\n",
      ", artifact_type: name: \"ModelEvaluation\"\n",
      ")]}), exec_properties={'eval_config': '{\\n  \"metrics_specs\": [\\n    {\\n      \"metrics\": [\\n        {\\n          \"class_name\": \"SparseCategoricalAccuracy\",\\n          \"threshold\": {\\n            \"change_threshold\": {\\n              \"absolute\": -1e-10,\\n              \"direction\": \"HIGHER_IS_BETTER\"\\n            },\\n            \"value_threshold\": {\\n              \"lower_bound\": 0.6\\n            }\\n          }\\n        }\\n      ]\\n    }\\n  ],\\n  \"model_specs\": [\\n    {\\n      \"label_key\": \"class\",\\n      \"preprocessing_function_names\": [\\n        \"transform_features\"\\n      ],\\n      \"signature_name\": \"serving_default\"\\n    }\\n  ],\\n  \"slicing_specs\": [\\n    {}\\n  ]\\n}', 'example_splits': 'null', 'fairness_indicator_thresholds': 'null'}, execution_output_uri='pipelines/iris/Evaluator/.system/executor_execution/471/executor_output.pb', stateful_working_dir='pipelines/iris/Evaluator/.system/stateful_working_dir/2021-11-30T11:37:57.542539', tmp_dir='pipelines/iris/Evaluator/.system/executor_execution/471/.temp/', pipeline_node=node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.evaluator.component.Evaluator\"\n",
      "  }\n",
      "  id: \"Evaluator\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"iris\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2021-11-30T11:37:57.542539\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"iris.Evaluator\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"baseline_model\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"latest_blessed_model_resolver\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"iris\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2021-11-30T11:37:57.542539\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"iris.latest_blessed_model_resolver\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Model\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"model\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"CsvExampleGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"iris\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2021-11-30T11:37:57.542539\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"iris.CsvExampleGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Examples\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"examples\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"model\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"Trainer\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"iris\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2021-11-30T11:37:57.542539\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"iris.Trainer\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Model\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"model\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"blessing\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ModelBlessing\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"evaluation\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ModelEvaluation\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"eval_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"metrics_specs\\\": [\\n    {\\n      \\\"metrics\\\": [\\n        {\\n          \\\"class_name\\\": \\\"SparseCategoricalAccuracy\\\",\\n          \\\"threshold\\\": {\\n            \\\"change_threshold\\\": {\\n              \\\"absolute\\\": -1e-10,\\n              \\\"direction\\\": \\\"HIGHER_IS_BETTER\\\"\\n            },\\n            \\\"value_threshold\\\": {\\n              \\\"lower_bound\\\": 0.6\\n            }\\n          }\\n        }\\n      ]\\n    }\\n  ],\\n  \\\"model_specs\\\": [\\n    {\\n      \\\"label_key\\\": \\\"class\\\",\\n      \\\"preprocessing_function_names\\\": [\\n        \\\"transform_features\\\"\\n      ],\\n      \\\"signature_name\\\": \\\"serving_default\\\"\\n    }\\n  ],\\n  \\\"slicing_specs\\\": [\\n    {}\\n  ]\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"example_splits\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"null\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"fairness_indicator_thresholds\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"null\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"CsvExampleGen\"\n",
      "upstream_nodes: \"Trainer\"\n",
      "upstream_nodes: \"latest_blessed_model_resolver\"\n",
      "downstream_nodes: \"Pusher\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      ", pipeline_info=id: \"iris\"\n",
      ", pipeline_run_id='2021-11-30T11:37:57.542539')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:udf_utils.get_fn {'eval_config': '{\\n  \"metrics_specs\": [\\n    {\\n      \"metrics\": [\\n        {\\n          \"class_name\": \"SparseCategoricalAccuracy\",\\n          \"threshold\": {\\n            \"change_threshold\": {\\n              \"absolute\": -1e-10,\\n              \"direction\": \"HIGHER_IS_BETTER\"\\n            },\\n            \"value_threshold\": {\\n              \"lower_bound\": 0.6\\n            }\\n          }\\n        }\\n      ]\\n    }\\n  ],\\n  \"model_specs\": [\\n    {\\n      \"label_key\": \"class\",\\n      \"preprocessing_function_names\": [\\n        \"transform_features\"\\n      ],\\n      \"signature_name\": \"serving_default\"\\n    }\\n  ],\\n  \"slicing_specs\": [\\n    {}\\n  ]\\n}', 'example_splits': 'null', 'fairness_indicator_thresholds': 'null'} 'custom_eval_shared_model'\n",
      "INFO:absl:Adding default baseline ModelSpec based on the candidate ModelSpec provided. The candidate model will be called \"candidate\" and the baseline will be called \"baseline\": updated_config=\n",
      "model_specs {\n",
      "  name: \"candidate\"\n",
      "  signature_name: \"serving_default\"\n",
      "  label_key: \"class\"\n",
      "  preprocessing_function_names: \"transform_features\"\n",
      "}\n",
      "model_specs {\n",
      "  name: \"baseline\"\n",
      "  signature_name: \"serving_default\"\n",
      "  label_key: \"class\"\n",
      "  is_baseline: true\n",
      "  preprocessing_function_names: \"transform_features\"\n",
      "}\n",
      "slicing_specs {\n",
      "}\n",
      "metrics_specs {\n",
      "  metrics {\n",
      "    class_name: \"SparseCategoricalAccuracy\"\n",
      "    threshold {\n",
      "      value_threshold {\n",
      "        lower_bound {\n",
      "          value: 0.6\n",
      "        }\n",
      "      }\n",
      "      change_threshold {\n",
      "        absolute {\n",
      "          value: -1e-10\n",
      "        }\n",
      "        direction: HIGHER_IS_BETTER\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "INFO:absl:Using pipelines/iris/Trainer/model/470/Format-Serving as candidate model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x7fbd054145e0> and <keras.engine.input_layer.InputLayer object at 0x7fbd0422a3a0>).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x7fbd054145e0> and <keras.engine.input_layer.InputLayer object at 0x7fbd0422a3a0>).\n",
      "INFO:absl:Using pipelines/iris/Trainer/model/420/Format-Serving as baseline model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x7fbd045d50a0> and <keras.engine.input_layer.InputLayer object at 0x7fbc04071220>).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x7fbd045d50a0> and <keras.engine.input_layer.InputLayer object at 0x7fbc04071220>).\n",
      "INFO:absl:The 'example_splits' parameter is not set, using 'eval' split.\n",
      "INFO:absl:Evaluating model.\n",
      "INFO:absl:udf_utils.get_fn {'eval_config': '{\\n  \"metrics_specs\": [\\n    {\\n      \"metrics\": [\\n        {\\n          \"class_name\": \"SparseCategoricalAccuracy\",\\n          \"threshold\": {\\n            \"change_threshold\": {\\n              \"absolute\": -1e-10,\\n              \"direction\": \"HIGHER_IS_BETTER\"\\n            },\\n            \"value_threshold\": {\\n              \"lower_bound\": 0.6\\n            }\\n          }\\n        }\\n      ]\\n    }\\n  ],\\n  \"model_specs\": [\\n    {\\n      \"label_key\": \"class\",\\n      \"preprocessing_function_names\": [\\n        \"transform_features\"\\n      ],\\n      \"signature_name\": \"serving_default\"\\n    }\\n  ],\\n  \"slicing_specs\": [\\n    {}\\n  ]\\n}', 'example_splits': 'null', 'fairness_indicator_thresholds': 'null'} 'custom_extractors'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x7fbbdc1100a0> and <keras.engine.input_layer.InputLayer object at 0x7fbbdc0e3af0>).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x7fbbdc1100a0> and <keras.engine.input_layer.InputLayer object at 0x7fbbdc0e3af0>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x7fbb6c32c5e0> and <keras.engine.input_layer.InputLayer object at 0x7fbb6c38be50>).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x7fbb6c32c5e0> and <keras.engine.input_layer.InputLayer object at 0x7fbb6c38be50>).\n",
      "WARNING:root:Make sure that locally built Python SDK docker image has Python 3.8 interpreter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x7fbb6c0737f0> and <keras.engine.input_layer.InputLayer object at 0x7fbb6c065250>).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x7fbb6c0737f0> and <keras.engine.input_layer.InputLayer object at 0x7fbb6c065250>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x7fbb64600a00> and <keras.engine.input_layer.InputLayer object at 0x7fbb6c3b8f10>).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x7fbb64600a00> and <keras.engine.input_layer.InputLayer object at 0x7fbb6c3b8f10>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x7fbb643e3be0> and <keras.engine.input_layer.InputLayer object at 0x7fbb643d5640>).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x7fbb643e3be0> and <keras.engine.input_layer.InputLayer object at 0x7fbb643d5640>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x7fbb64140c70> and <keras.engine.input_layer.InputLayer object at 0x7fbb641a9310>).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x7fbb64140c70> and <keras.engine.input_layer.InputLayer object at 0x7fbb641a9310>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x7fbb34678880> and <keras.engine.input_layer.InputLayer object at 0x7fbb34670730>).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x7fbb34678880> and <keras.engine.input_layer.InputLayer object at 0x7fbb34670730>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x7fbb240c5df0> and <keras.engine.input_layer.InputLayer object at 0x7fbb24131ca0>).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x7fbb240c5df0> and <keras.engine.input_layer.InputLayer object at 0x7fbb24131ca0>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x7fbb0c5a6cd0> and <keras.engine.input_layer.InputLayer object at 0x7fbb0c59dc40>).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x7fbb0c5a6cd0> and <keras.engine.input_layer.InputLayer object at 0x7fbb0c59dc40>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x7fbb0c386f10> and <keras.engine.input_layer.InputLayer object at 0x7fbb0c36f2b0>).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x7fbb0c386f10> and <keras.engine.input_layer.InputLayer object at 0x7fbb0c36f2b0>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x7fbb0c0f9d90> and <keras.engine.input_layer.InputLayer object at 0x7fbb0c0e6d00>).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x7fbb0c0f9d90> and <keras.engine.input_layer.InputLayer object at 0x7fbb0c0e6d00>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x7fbafee56e50> and <keras.engine.input_layer.InputLayer object at 0x7fbafee416a0>).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x7fbafee56e50> and <keras.engine.input_layer.InputLayer object at 0x7fbafee416a0>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x7fbafebeae20> and <keras.engine.input_layer.InputLayer object at 0x7fbafebddca0>).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x7fbafebeae20> and <keras.engine.input_layer.InputLayer object at 0x7fbafebddca0>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x7fbafe950760> and <keras.engine.input_layer.InputLayer object at 0x7fbafe9ae850>).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x7fbafe950760> and <keras.engine.input_layer.InputLayer object at 0x7fbafe9ae850>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x7fbafe728ac0> and <keras.engine.input_layer.InputLayer object at 0x7fbafe71b520>).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x7fbafe728ac0> and <keras.engine.input_layer.InputLayer object at 0x7fbafe71b520>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x7fbafe483670> and <keras.engine.input_layer.InputLayer object at 0x7fbafe4e2a30>).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x7fbafe483670> and <keras.engine.input_layer.InputLayer object at 0x7fbafe4e2a30>).\n",
      "INFO:absl:Evaluation complete. Results written to pipelines/iris/Evaluator/evaluation/471.\n",
      "INFO:absl:Checking validation results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ekrem/.pyenv/versions/3.8.7/envs/tfx/lib/python3.8/site-packages/tensorflow_model_analysis/writers/metrics_plots_and_validations_writer.py:114: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ekrem/.pyenv/versions/3.8.7/envs/tfx/lib/python3.8/site-packages/tensorflow_model_analysis/writers/metrics_plots_and_validations_writer.py:114: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n",
      "INFO:absl:Blessing result False written to pipelines/iris/Evaluator/blessing/471.\n",
      "INFO:absl:Cleaning up stateless execution info.\n",
      "INFO:absl:Execution 471 succeeded.\n",
      "INFO:absl:Cleaning up stateful execution info.\n",
      "INFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'blessing': [Artifact(artifact: uri: \"pipelines/iris/Evaluator/blessing/471\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"iris:2021-11-30T11:37:57.542539:Evaluator:blessing:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.4.0\"\n",
      "  }\n",
      "}\n",
      ", artifact_type: name: \"ModelBlessing\"\n",
      ")], 'evaluation': [Artifact(artifact: uri: \"pipelines/iris/Evaluator/evaluation/471\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"iris:2021-11-30T11:37:57.542539:Evaluator:evaluation:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.4.0\"\n",
      "  }\n",
      "}\n",
      ", artifact_type: name: \"ModelEvaluation\"\n",
      ")]}) for execution 471\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Component Evaluator is finished.\n",
      "INFO:absl:Component Pusher is running.\n",
      "INFO:absl:Running launcher for node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.pusher.component.Pusher\"\n",
      "  }\n",
      "  id: \"Pusher\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"iris\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2021-11-30T11:37:57.542539\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"iris.Pusher\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"model\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"Trainer\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"iris\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2021-11-30T11:37:57.542539\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"iris.Trainer\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Model\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"model\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"model_blessing\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"Evaluator\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"iris\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2021-11-30T11:37:57.542539\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"iris.Evaluator\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"ModelBlessing\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"blessing\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"pushed_model\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"PushedModel\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"custom_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"null\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"push_destination\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"filesystem\\\": {\\n    \\\"base_directory\\\": \\\"serving_model/iris\\\"\\n  }\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"Evaluator\"\n",
      "upstream_nodes: \"Trainer\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      "\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Going to run a new execution 472\n",
      "INFO:absl:Going to run a new execution: ExecutionInfo(execution_id=472, input_dict={'model_blessing': [Artifact(artifact: id: 813\n",
      "type_id: 34\n",
      "uri: \"pipelines/iris/Evaluator/blessing/471\"\n",
      "custom_properties {\n",
      "  key: \"baseline_model\"\n",
      "  value {\n",
      "    string_value: \"pipelines/iris/Trainer/model/420\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"baseline_model_id\"\n",
      "  value {\n",
      "    int_value: 726\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"blessed\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"current_model\"\n",
      "  value {\n",
      "    string_value: \"pipelines/iris/Trainer/model/470\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"current_model_id\"\n",
      "  value {\n",
      "    int_value: 812\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"iris:2021-11-30T11:37:57.542539:Evaluator:blessing:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.4.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "create_time_since_epoch: 1638268728885\n",
      "last_update_time_since_epoch: 1638268728885\n",
      ", artifact_type: id: 34\n",
      "name: \"ModelBlessing\"\n",
      ")], 'model': [Artifact(artifact: id: 812\n",
      "type_id: 28\n",
      "uri: \"pipelines/iris/Trainer/model/470\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"iris:2021-11-30T11:37:57.542539:Trainer:model:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.4.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "create_time_since_epoch: 1638268719029\n",
      "last_update_time_since_epoch: 1638268719029\n",
      ", artifact_type: id: 28\n",
      "name: \"Model\"\n",
      ")]}, output_dict=defaultdict(<class 'list'>, {'pushed_model': [Artifact(artifact: uri: \"pipelines/iris/Pusher/pushed_model/472\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"iris:2021-11-30T11:37:57.542539:Pusher:pushed_model:0\"\n",
      "  }\n",
      "}\n",
      ", artifact_type: name: \"PushedModel\"\n",
      ")]}), exec_properties={'custom_config': 'null', 'push_destination': '{\\n  \"filesystem\": {\\n    \"base_directory\": \"serving_model/iris\"\\n  }\\n}'}, execution_output_uri='pipelines/iris/Pusher/.system/executor_execution/472/executor_output.pb', stateful_working_dir='pipelines/iris/Pusher/.system/stateful_working_dir/2021-11-30T11:37:57.542539', tmp_dir='pipelines/iris/Pusher/.system/executor_execution/472/.temp/', pipeline_node=node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.pusher.component.Pusher\"\n",
      "  }\n",
      "  id: \"Pusher\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"iris\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2021-11-30T11:37:57.542539\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"iris.Pusher\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"model\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"Trainer\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"iris\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2021-11-30T11:37:57.542539\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"iris.Trainer\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Model\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"model\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"model_blessing\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"Evaluator\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"iris\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2021-11-30T11:37:57.542539\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"iris.Evaluator\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"ModelBlessing\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"blessing\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"pushed_model\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"PushedModel\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"custom_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"null\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"push_destination\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"filesystem\\\": {\\n    \\\"base_directory\\\": \\\"serving_model/iris\\\"\\n  }\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"Evaluator\"\n",
      "upstream_nodes: \"Trainer\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      ", pipeline_info=id: \"iris\"\n",
      ", pipeline_run_id='2021-11-30T11:37:57.542539')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Model on pipelines/iris/Evaluator/blessing/471 was not blessed by model validation\n",
      "INFO:absl:Cleaning up stateless execution info.\n",
      "INFO:absl:Execution 472 succeeded.\n",
      "INFO:absl:Cleaning up stateful execution info.\n",
      "INFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'pushed_model': [Artifact(artifact: uri: \"pipelines/iris/Pusher/pushed_model/472\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"iris:2021-11-30T11:37:57.542539:Pusher:pushed_model:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.4.0\"\n",
      "  }\n",
      "}\n",
      ", artifact_type: name: \"PushedModel\"\n",
      ")]}) for execution 472\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Component Pusher is finished.\n"
     ]
    }
   ],
   "source": [
    "tfx.orchestration.LocalDagRunner().run(pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tfx.orchestration.portable.mlmd import execution_lib\n",
    "from tfx.orchestration.metadata import Metadata\n",
    "from tfx.orchestration.experimental.interactive import visualizations\n",
    "from ml_metadata.proto import metadata_store_pb2\n",
    "\n",
    "def get_latest_artifact(component_id):\n",
    "    metadata_connection_config = tfx.orchestration.metadata.sqlite_metadata_connection_config(METADATA_PATH)\n",
    "\n",
    "    with Metadata(metadata_connection_config) as metadata_handler:\n",
    "        context = metadata_handler.store.get_context_by_type_and_name('node', f'{PIPELINE_NAME}.{component_id}')\n",
    "        executions = metadata_handler.store.get_executions_by_context(context.id)\n",
    "        latest_execution = max(executions, key=lambda e: e.last_update_time_since_epoch)\n",
    "\n",
    "        return execution_lib.get_artifacts_dict(metadata_handler, latest_execution.id, [metadata_store_pb2.Event.OUTPUT])\n",
    "\n",
    "\n",
    "def visualize(artifact):\n",
    "    visualization = visualizations.get_registry().get_visualization(artifact.type_name)\n",
    "    visualization.display(artifact)\n",
    "\n",
    "\n",
    "from tfx.orchestration.experimental.interactive import standard_visualizations\n",
    "\n",
    "standard_visualizations.register_standard_visualizations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StatisticsGen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:MetadataStore with DB connection initialized\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><b>'train' split:</b></div><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<iframe id='facets-iframe' width=\"100%\" height=\"500px\"></iframe>\n",
       "        <script>\n",
       "        facets_iframe = document.getElementById('facets-iframe');\n",
       "        facets_html = '<script src=\"https://cdnjs.cloudflare.com/ajax/libs/webcomponentsjs/1.3.3/webcomponents-lite.js\"><\\/script><link rel=\"import\" href=\"https://raw.githubusercontent.com/PAIR-code/facets/master/facets-dist/facets-jupyter.html\"><facets-overview proto-input=\"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\"></facets-overview>';\n",
       "        facets_iframe.srcdoc = facets_html;\n",
       "         facets_iframe.id = \"\";\n",
       "         setTimeout(() => {\n",
       "           facets_iframe.setAttribute('height', facets_iframe.contentWindow.document.body.offsetHeight + 'px')\n",
       "         }, 1500)\n",
       "         </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><b>'eval' split:</b></div><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<iframe id='facets-iframe' width=\"100%\" height=\"500px\"></iframe>\n",
       "        <script>\n",
       "        facets_iframe = document.getElementById('facets-iframe');\n",
       "        facets_html = '<script src=\"https://cdnjs.cloudflare.com/ajax/libs/webcomponentsjs/1.3.3/webcomponents-lite.js\"><\\/script><link rel=\"import\" href=\"https://raw.githubusercontent.com/PAIR-code/facets/master/facets-dist/facets-jupyter.html\"><facets-overview proto-input=\"CqMiCg5saHNfc3RhdGlzdGljcxA2GvQDEAIi5gMKtAIINhgBIAEtAACAPzKkAhobCQAAAAAAAPA/EQAAAAAAAPA/IZqZmZmZmRVAGhsJAAAAAAAA8D8RAAAAAAAA8D8hmpmZmZmZFUAaGwkAAAAAAADwPxEAAAAAAADwPyGamZmZmZkVQBobCQAAAAAAAPA/EQAAAAAAAPA/IZqZmZmZmRVAGhsJAAAAAAAA8D8RAAAAAAAA8D8hmpmZmZmZFUAaGwkAAAAAAADwPxEAAAAAAADwPyGamZmZmZkVQBobCQAAAAAAAPA/EQAAAAAAAPA/IZqZmZmZmRVAGhsJAAAAAAAA8D8RAAAAAAAA8D8hmpmZmZmZFUAaGwkAAAAAAADwPxEAAAAAAADwPyGamZmZmZkVQBobCQAAAAAAAPA/EQAAAAAAAPA/IZqZmZmZmRVAIAFANhADGhkSDklyaXMtdmlyZ2luaWNhGQAAAAAAADRAGhYSC0lyaXMtc2V0b3NhGQAAAAAAADNAGhoSD0lyaXMtdmVyc2ljb2xvchkAAAAAAAAuQCU5jlNBKlcKGSIOSXJpcy12aXJnaW5pY2EpAAAAAAAANEAKGggBEAEiC0lyaXMtc2V0b3NhKQAAAAAAADNACh4IAhACIg9JcmlzLXZlcnNpY29sb3IpAAAAAAAALkBCBwoFY2xhc3MaxAcQARqwBwq0Agg2GAEgAS0AAIA/MqQCGhsJAAAAAAAA8D8RAAAAAAAA8D8hmpmZmZmZFUAaGwkAAAAAAADwPxEAAAAAAADwPyGamZmZmZkVQBobCQAAAAAAAPA/EQAAAAAAAPA/IZqZmZmZmRVAGhsJAAAAAAAA8D8RAAAAAAAA8D8hmpmZmZmZFUAaGwkAAAAAAADwPxEAAAAAAADwPyGamZmZmZkVQBobCQAAAAAAAPA/EQAAAAAAAPA/IZqZmZmZmRVAGhsJAAAAAAAA8D8RAAAAAAAA8D8hmpmZmZmZFUAaGwkAAAAAAADwPxEAAAAAAADwPyGamZmZmZkVQBobCQAAAAAAAPA/EQAAAAAAAPA/IZqZmZmZmRVAGhsJAAAAAAAA8D8RAAAAAAAA8D8hmpmZmZmZFUAgAUA2ES+hvfz//w1AGapgf8pudf0/KQAAAAAAAPA/MQAAAKCZmRFAOQAAAKCZmRtAQqICGhsJAAAAAAAA8D8RmpmZ2aNw+T8hnDMieVgIMEAaGwmamZnZo3D5PxGamZnZo3ABQCEIk6m2hHwHQBobCZqZmdmjcAFAEWZmZsb1KAZAIREIh/HyH5I/GhsJZmZmxvUoBkARMzMzs0fhCkAhFQiH8fIfkj8aGwkzMzOzR+EKQBEAAACgmZkPQCEq82mwlGXwPxobCQAAAKCZmQ9AEWZmZsb1KBJAIQxE+p2A5idAGhsJZmZmxvUoEkARzczMvB6FFEAhSZjdu2L/F0AaGwnNzMy8HoUUQBEzMzOzR+EWQCFrR799HfgjQBobCTMzM7NH4RZAEZmZmalwPRlAIYTnP6wRCBBAGhsJmZmZqXA9GUARAAAAoJmZG0Ah54woHQw8AEBCpAIaGwkAAAAAAADwPxEAAADAzMz0PyGamZmZmZkVQBobCQAAAMDMzPQ/EQAAAGBmZvY/IZqZmZmZmRVAGhsJAAAAYGZm9j8RAAAAoJmZ+T8hmpmZmZmZFUAaGwkAAACgmZn5PxEAAAAAAAAQQCGamZmZmZkVQBobCQAAAAAAABBAEQAAAKCZmRFAIZqZmZmZmRVAGhsJAAAAoJmZEUARAAAAwMzMEkAhmpmZmZmZFUAaGwkAAADAzMwSQBEAAABgZmYUQCGamZmZmZkVQBobCQAAAGBmZhRAEQAAAGBmZhZAIZqZmZmZmRVAGhsJAAAAYGZmFkARAAAAQDMzF0AhmpmZmZmZFUAaGwkAAABAMzMXQBEAAACgmZkbQCGamZmZmZkVQCABQg0KC3BldGFsbGVuZ3RoGsMHEAEasAcKtAIINhgBIAEtAACAPzKkAhobCQAAAAAAAPA/EQAAAAAAAPA/IZqZmZmZmRVAGhsJAAAAAAAA8D8RAAAAAAAA8D8hmpmZmZmZFUAaGwkAAAAAAADwPxEAAAAAAADwPyGamZmZmZkVQBobCQAAAAAAAPA/EQAAAAAAAPA/IZqZmZmZmRVAGhsJAAAAAAAA8D8RAAAAAAAA8D8hmpmZmZmZFUAaGwkAAAAAAADwPxEAAAAAAADwPyGamZmZmZkVQBobCQAAAAAAAPA/EQAAAAAAAPA/IZqZmZmZmRVAGhsJAAAAAAAA8D8RAAAAAAAA8D8hmpmZmZmZFUAaGwkAAAAAAADwPxEAAAAAAADwPyGamZmZmZkVQBobCQAAAAAAAPA/EQAAAAAAAPA/IZqZmZmZmRVAIAFANhGO4zhYsAXzPxnqF6OnSz3pPykAAACgmZnJPzEAAADAzMz0PzkAAAAAAAAEQEKiAhobCQAAAKCZmck/ETMzM7sehds/IWPuikrq9DJAGhsJMzMzux6F2z8RMzMzU7ge5T8h6Uguf2EylT8aGwkzMzNTuB7lPxHMzMxI4XrsPyHnSC5/YTKVPxobCczMzEjheuw/ETMzMx+F6/E/IcAFEr0wGQhAGhsJMzMzH4Xr8T8RAAAAmpmZ9T8he1HJkFP0F0AaGwkAAACamZn1PxHMzMwUrkf5PyFdMGrccQoYQBobCczMzBSuR/k/EZmZmY/C9fw/If7NWdAZ0R9AGhsJmZmZj8L1/D8RMzMzhetRAEAhJJYy4xQdAEAaGwkzMzOF61EAQBGZmZnC9SgCQCFI0HMb62IIQBobCZmZmcL1KAJAEQAAAAAAAARAIfVjbHd65RtAQqQCGhsJAAAAoJmZyT8RAAAAoJmZyT8hmpmZmZmZFUAaGwkAAACgmZnJPxEAAACgmZnJPyGamZmZmZkVQBobCQAAAKCZmck/EQAAAEAzM9M/IZqZmZmZmRVAGhsJAAAAQDMz0z8RAAAAAAAA8D8hmpmZmZmZFUAaGwkAAAAAAADwPxEAAADAzMz0PyGamZmZmZkVQBobCQAAAMDMzPQ/EQAAAAAAAPg/IZqZmZmZmRVAGhsJAAAAAAAA+D8RAAAAwMzM/D8hmpmZmZmZFUAaGwkAAADAzMz8PxEAAAAAAAAAQCGamZmZmZkVQBobCQAAAAAAAABAEQAAAGBmZgJAIZqZmZmZmRVAGhsJAAAAYGZmAkARAAAAAAAABEAhmpmZmZmZFUAgAUIMCgpwZXRhbHdpZHRoGsQHEAEasAcKtAIINhgBIAEtAACAPzKkAhobCQAAAAAAAPA/EQAAAAAAAPA/IZqZmZmZmRVAGhsJAAAAAAAA8D8RAAAAAAAA8D8hmpmZmZmZFUAaGwkAAAAAAADwPxEAAAAAAADwPyGamZmZmZkVQBobCQAAAAAAAPA/EQAAAAAAAPA/IZqZmZmZmRVAGhsJAAAAAAAA8D8RAAAAAAAA8D8hmpmZmZmZFUAaGwkAAAAAAADwPxEAAAAAAADwPyGamZmZmZkVQBobCQAAAAAAAPA/EQAAAAAAAPA/IZqZmZmZmRVAGhsJAAAAAAAA8D8RAAAAAAAA8D8hmpmZmZmZFUAaGwkAAAAAAADwPxEAAAAAAADwPyGamZmZmZkVQBobCQAAAAAAAPA/EQAAAAAAAPA/IZqZmZmZmRVAIAFANhHHcRyHiIgXQBmLvgXTwtPrPykAAACgmZkRQDEAAABAMzMXQDkAAADAzMweQEKiAhobCQAAAKCZmRFAETMzMyOF6xJAIQN2T3x65RtAGhsJMzMzI4XrEkARZmZmpnA9FEAhJaH4Q2kvFEAaGwlmZmamcD0UQBGamZkpXI8VQCFJVFLtQQ8QQBobCZqZmSlcjxVAEc3MzKxH4RZAIVH3UwDV2CFAGhsJzczMrEfhFkARAAAAMDMzGEAhabprmRElHEAaGwkAAAAwMzMYQBEzMzOzHoUZQCE1kjohfgwQQBobCTMzM7MehRlAEWZmZjYK1xpAIZf/kMrc9SFAGhsJZmZmNgrXGkARmpmZufUoHEAhNq361IHzE0AaGwmamZm59SgcQBHMzMw84XodQCH86dl0SL/wPxobCczMzDzheh1AEQAAAMDMzB5AIdtkiB8m0wdAQqQCGhsJAAAAoJmZEUARAAAAYGZmEkAhmpmZmZmZFUAaGwkAAABgZmYSQBEAAAAAAAAUQCGamZmZmZkVQBobCQAAAAAAABRAEQAAAKCZmRVAIZqZmZmZmRVAGhsJAAAAoJmZFUARAAAAwMzMFkAhmpmZmZmZFUAaGwkAAADAzMwWQBEAAABAMzMXQCGamZmZmZkVQBobCQAAAEAzMxdAEQAAAGBmZhhAIZqZmZmZmRVAGhsJAAAAYGZmGEARAAAAAAAAGkAhmpmZmZmZFUAaGwkAAAAAAAAaQBEAAADAzMwaQCGamZmZmZkVQBobCQAAAMDMzBpAEQAAAKCZmRtAIZqZmZmZmRVAGhsJAAAAoJmZG0ARAAAAwMzMHkAhmpmZmZmZFUAgAUINCgtzZXBhbGxlbmd0aBrDBxABGrAHCrQCCDYYASABLQAAgD8ypAIaGwkAAAAAAADwPxEAAAAAAADwPyGamZmZmZkVQBobCQAAAAAAAPA/EQAAAAAAAPA/IZqZmZmZmRVAGhsJAAAAAAAA8D8RAAAAAAAA8D8hmpmZmZmZFUAaGwkAAAAAAADwPxEAAAAAAADwPyGamZmZmZkVQBobCQAAAAAAAPA/EQAAAAAAAPA/IZqZmZmZmRVAGhsJAAAAAAAA8D8RAAAAAAAA8D8hmpmZmZmZFUAaGwkAAAAAAADwPxEAAAAAAADwPyGamZmZmZkVQBobCQAAAAAAAPA/EQAAAAAAAPA/IZqZmZmZmRVAGhsJAAAAAAAA8D8RAAAAAAAA8D8hmpmZmZmZFUAaGwkAAAAAAADwPxEAAAAAAADwPyGamZmZmZkVQCABQDYRhfYSqqqqCEAZTxITTvbO2z8pAAAAoJmZAUAxAAAAwMzMCEA5AAAAoJmZEUBCogIaGwkAAACgmZkBQBHNzMz8KFwDQCGXZYg7AU0AQBobCc3MzPwoXANAEZqZmVm4HgVAIRoSg0Rg5R9AGhsJmpmZWbgeBUARZmZmtkfhBkAhhr99iUrqE0AaGwlmZma2R+EGQBEzMzMT16MIQCHBBvC8uA0mQBobCTMzMxPXowhAEQAAAHBmZgpAIWiPMYmw4S9AGhsJAAAAcGZmCkARzczMzPUoDEAhug3gUZYhFEAaGwnNzMzM9SgMQBGamZkphesNQCF61HgxMzMAQBobCZqZmSmF6w1AEWZmZoYUrg9AIe1nszKAtwdAGhsJZmZmhhSuD0ARmpmZ8VG4EEAh93d6fVFJ8D8aGwmamZnxUbgQQBEAAACgmZkRQCFTFYyS9gbwP0KkAhobCQAAAKCZmQFAEQAAAMDMzARAIZqZmZmZmRVAGhsJAAAAwMzMBEARAAAAoJmZBUAhmpmZmZmZFUAaGwkAAACgmZkFQBEAAABAMzMHQCGamZmZmZkVQBobCQAAAEAzMwdAEQAAAAAAAAhAIZqZmZmZmRVAGhsJAAAAAAAACEARAAAAwMzMCEAhmpmZmZmZFUAaGwkAAADAzMwIQBEAAACgmZkJQCGamZmZmZkVQBobCQAAAKCZmQlAEQAAAKCZmQlAIZqZmZmZmRVAGhsJAAAAoJmZCUARAAAAQDMzC0AhmpmZmZmZFUAaGwkAAABAMzMLQBEAAADAzMwMQCGamZmZmZkVQBobCQAAAMDMzAxAEQAAAKCZmRFAIZqZmZmZmRVAIAFCDAoKc2VwYWx3aWR0aA==\"></facets-overview>';\n",
       "        facets_iframe.srcdoc = facets_html;\n",
       "         facets_iframe.id = \"\";\n",
       "         setTimeout(() => {\n",
       "           facets_iframe.setAttribute('height', facets_iframe.contentWindow.document.body.offsetHeight + 'px')\n",
       "         }, 1500)\n",
       "         </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "statistic_artifact = get_latest_artifact(\"StatisticsGen\")['statistics'][0]\n",
    "\n",
    "visualize(statistic_artifact)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SchemaGen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:MetadataStore with DB connection initialized\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Presence</th>\n",
       "      <th>Valency</th>\n",
       "      <th>Domain</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>'class'</th>\n",
       "      <td>STRING</td>\n",
       "      <td>required</td>\n",
       "      <td></td>\n",
       "      <td>'class'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'petallength'</th>\n",
       "      <td>FLOAT</td>\n",
       "      <td>required</td>\n",
       "      <td></td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'petalwidth'</th>\n",
       "      <td>FLOAT</td>\n",
       "      <td>required</td>\n",
       "      <td></td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'sepallength'</th>\n",
       "      <td>FLOAT</td>\n",
       "      <td>required</td>\n",
       "      <td></td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'sepalwidth'</th>\n",
       "      <td>FLOAT</td>\n",
       "      <td>required</td>\n",
       "      <td></td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Type  Presence Valency   Domain\n",
       "Feature name                                    \n",
       "'class'        STRING  required          'class'\n",
       "'petallength'   FLOAT  required                -\n",
       "'petalwidth'    FLOAT  required                -\n",
       "'sepallength'   FLOAT  required                -\n",
       "'sepalwidth'    FLOAT  required                -"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Values</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Domain</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>'class'</th>\n",
       "      <td>'Iris-setosa', 'Iris-versicolor', 'Iris-virginica'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Values\n",
       "Domain                                                     \n",
       "'class'  'Iris-setosa', 'Iris-versicolor', 'Iris-virginica'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "schema_artifact = get_latest_artifact(\"SchemaGen\")['schema'][0]\n",
    "\n",
    "visualize(schema_artifact)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ExampleValidator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:MetadataStore with DB connection initialized\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><b>'train' split:</b></div><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h4 style=\"color:green;\">No anomalies found.</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><b>'eval' split:</b></div><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h4 style=\"color:green;\">No anomalies found.</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "example_validator_articaft = get_latest_artifact(\"ExampleValidator\")['anomalies'][0]\n",
    "\n",
    "visualize(example_validator_articaft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:MetadataStore with DB connection initialized\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-d183cdc90bca91a\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-d183cdc90bca91a\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tuner_articaft = get_latest_artifact(\"Tuner\")[\"best_hyperparameters\"][0]\n",
    "\n",
    "tuner_tensorboard = os.path.join(\n",
    "    tuner_articaft.uri[0:(len('Tuner') + tuner_articaft.uri.index('Tuner'))],\n",
    "    \"tensorboards\",\n",
    "    os.path.split(tuner_articaft.uri.strip(\"/\"))[-1]\n",
    ")\n",
    "\n",
    "\n",
    "%tensorboard --logdir {tuner_tensorboard}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:MetadataStore with DB connection initialized\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-5570d0e314dc5ca0\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-5570d0e314dc5ca0\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_run_artifact_dir = get_latest_artifact(\"Trainer\")['model_run'][0].uri\n",
    "\n",
    "%tensorboard --logdir {model_run_artifact_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:MetadataStore with DB connection initialized\n"
     ]
    }
   ],
   "source": [
    "schema_artifact = get_latest_artifact(\"Evaluator\")['evaluation'][0]\n",
    "\n",
    "visualize(schema_artifact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fef94dee998408aacdc64c720a7cde0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SlicingMetricsViewer(config={'weightedExamplesColumn': 'example_count'}, data=[{'slice': 'Overall', 'metrics':"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the TFMA output result path and load the result.\n",
    "tfma_result = tfma.load_eval_result(schema_artifact.uri)\n",
    "\n",
    "# Show data sliced along feature column trip_start_hour.\n",
    "tfma.view.render_slicing_metrics(tfma_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Serve"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Serve the resulting model by running this in your shell:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "``$ tensorflow_model_server --rest_api_port=8501 --model_name=iris --model_base_path=/home/ekrem/Workplace/Python/tfx_seminar/serving_model/iris``"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown as md\n",
    "from IPython.display import display\n",
    "\n",
    "serving_cmd = !pwd\n",
    "serving_cmd = f\"tensorflow_model_server --rest_api_port=8501 --model_name={PIPELINE_NAME} --model_base_path={os.path.join(serving_cmd[0], 'serving_model', PIPELINE_NAME)}\"\n",
    "\n",
    "display(md(\"# Serve\"))\n",
    "display(md(\"Serve the resulting model by running this in your shell:\"))\n",
    "display(md(f\"``$ {serving_cmd}``\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import base64\n",
    "import requests\n",
    "\n",
    "URL = 'http://localhost:8501/v1/models/' + PIPELINE_NAME + ':predict'\n",
    "HEADERS = {\"content-type\": \"application/json\"}\n",
    "\n",
    "def prediction_request(sepallength, sepalwidth, petallength, petalwidth):\n",
    "    features = {\n",
    "        'petallength': tf.train.Feature(float_list=tf.train.FloatList(value=[petallength])),\n",
    "        'petalwidth': tf.train.Feature(float_list=tf.train.FloatList(value=[petalwidth])),\n",
    "        'sepallength': tf.train.Feature(float_list=tf.train.FloatList(value=[sepallength])),\n",
    "        'sepalwidth': tf.train.Feature(float_list=tf.train.FloatList(value=[sepalwidth])),\n",
    "    }\n",
    "    example_proto = tf.train.Example(features=tf.train.Features(feature=features))\n",
    "    examples = example_proto.SerializeToString()\n",
    "\n",
    "    request_data = json.dumps({\n",
    "        \"signature_name\": \"serving_default\",\n",
    "        \"instances\": [{\n",
    "            \"examples\": {\"b64\": base64.b64encode(examples).decode('utf-8')}\n",
    "        }]\n",
    "    })\n",
    "\n",
    "    response = requests.post(data=request_data, url=URL, headers=HEADERS)\n",
    "\n",
    "    return json.loads(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "HTTPConnectionPool(host='localhost', port=8501): Max retries exceeded with url: /v1/models/iris:predict (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fbafe0ad820>: Failed to establish a new connection: [Errno 111] Connection refused'))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/.pyenv/versions/3.8.7/envs/tfx/lib/python3.8/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m             conn = connection.create_connection(\n\u001b[0m\u001b[1;32m    175\u001b[0m                 \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dns_host\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mextra_kw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.7/envs/tfx/lib/python3.8/site-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.7/envs/tfx/lib/python3.8/site-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 111] Connection refused",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m~/.pyenv/versions/3.8.7/envs/tfx/lib/python3.8/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    698\u001b[0m             \u001b[0;31m# Make the request on the httplib connection object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m             httplib_response = self._make_request(\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.7/envs/tfx/lib/python3.8/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m                 \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhttplib_request_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.7/envs/tfx/lib/python3.8/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, body, headers)\u001b[0m\n\u001b[1;32m    238\u001b[0m             \u001b[0mheaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"User-Agent\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_default_user_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHTTPConnection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.7/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1254\u001b[0m         \u001b[0;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.7/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36m_send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1300\u001b[0m             \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'body'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1301\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.7/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mendheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1249\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1250\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.7/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36m_send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1009\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1011\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.7/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    949\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.7/envs/tfx/lib/python3.8/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m         \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.7/envs/tfx/lib/python3.8/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSocketError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m             raise NewConnectionError(\n\u001b[0m\u001b[1;32m    187\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Failed to establish a new connection: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPConnection object at 0x7fbafe0ad820>: Failed to establish a new connection: [Errno 111] Connection refused",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/.pyenv/versions/3.8.7/envs/tfx/lib/python3.8/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchunked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m                 resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    440\u001b[0m                     \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.7/envs/tfx/lib/python3.8/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 755\u001b[0;31m             retries = retries.increment(\n\u001b[0m\u001b[1;32m    756\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_pool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacktrace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.7/envs/tfx/lib/python3.8/site-packages/urllib3/util/retry.py\u001b[0m in \u001b[0;36mincrement\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    573\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_retry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_exhausted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 574\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mMaxRetryError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPConnectionPool(host='localhost', port=8501): Max retries exceeded with url: /v1/models/iris:predict (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fbafe0ad820>: Failed to establish a new connection: [Errno 111] Connection refused'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_25523/3697487635.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m prediction_request(sepallength=4.4,\n\u001b[0m\u001b[1;32m      2\u001b[0m                    \u001b[0msepalwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                    \u001b[0mpetallength\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                    petalwidth=0.2)\n",
      "\u001b[0;32m/tmp/ipykernel_25523/2168843142.py\u001b[0m in \u001b[0;36mprediction_request\u001b[0;34m(sepallength, sepalwidth, petallength, petalwidth)\u001b[0m\n\u001b[1;32m     23\u001b[0m     })\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mURL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mHEADERS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.7/envs/tfx/lib/python3.8/site-packages/requests/api.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \"\"\"\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'post'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.7/envs/tfx/lib/python3.8/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.7/envs/tfx/lib/python3.8/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    540\u001b[0m         }\n\u001b[1;32m    541\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.7/envs/tfx/lib/python3.8/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.7/envs/tfx/lib/python3.8/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    514\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mSSLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mClosedPoolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionError\u001b[0m: HTTPConnectionPool(host='localhost', port=8501): Max retries exceeded with url: /v1/models/iris:predict (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fbafe0ad820>: Failed to establish a new connection: [Errno 111] Connection refused'))"
     ]
    }
   ],
   "source": [
    "prediction_request(sepallength=4.4,\n",
    "                   sepalwidth=3.2,\n",
    "                   petallength=1.3,\n",
    "                   petalwidth=0.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
